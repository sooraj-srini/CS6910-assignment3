{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Read the data"]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2023-05-16T06:34:37.819665Z","iopub.status.busy":"2023-05-16T06:34:37.818597Z","iopub.status.idle":"2023-05-16T06:34:51.401178Z","shell.execute_reply":"2023-05-16T06:34:51.399867Z","shell.execute_reply.started":"2023-05-16T06:34:37.819615Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: lightning in /opt/conda/lib/python3.7/site-packages (1.9.5)\n","Requirement already satisfied: wandb in /opt/conda/lib/python3.7/site-packages (0.14.0)\n","Requirement already satisfied: lightning-cloud>=0.5.27 in /opt/conda/lib/python3.7/site-packages (from lightning) (0.5.36)\n","Requirement already satisfied: torch<4.0,>=1.10.0 in /opt/conda/lib/python3.7/site-packages (from lightning) (1.13.0)\n","Requirement already satisfied: tqdm<6.0,>=4.57.0 in /opt/conda/lib/python3.7/site-packages (from lightning) (4.64.1)\n","Requirement already satisfied: starlette<2.0 in /opt/conda/lib/python3.7/site-packages (from lightning) (0.22.0)\n","Requirement already satisfied: urllib3<3.0 in /opt/conda/lib/python3.7/site-packages (from lightning) (1.26.14)\n","Requirement already satisfied: typing-extensions<6.0,>=4.0.0 in /opt/conda/lib/python3.7/site-packages (from lightning) (4.4.0)\n","Requirement already satisfied: numpy<3.0,>=1.17.2 in /opt/conda/lib/python3.7/site-packages (from lightning) (1.21.6)\n","Requirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from lightning) (23.0)\n","Requirement already satisfied: dateutils<2.0 in /opt/conda/lib/python3.7/site-packages (from lightning) (0.6.12)\n","Requirement already satisfied: lightning-utilities<2.0,>=0.6.0.post0 in /opt/conda/lib/python3.7/site-packages (from lightning) (0.8.0)\n","Requirement already satisfied: croniter<1.4.0,>=1.3.0 in /opt/conda/lib/python3.7/site-packages (from lightning) (1.3.14)\n","Requirement already satisfied: starsessions<2.0,>=1.2.1 in /opt/conda/lib/python3.7/site-packages (from lightning) (1.3.0)\n","Requirement already satisfied: psutil<7.0 in /opt/conda/lib/python3.7/site-packages (from lightning) (5.9.3)\n","Requirement already satisfied: beautifulsoup4<6.0,>=4.8.0 in /opt/conda/lib/python3.7/site-packages (from lightning) (4.11.1)\n","Requirement already satisfied: pydantic<3.0 in /opt/conda/lib/python3.7/site-packages (from lightning) (1.10.4)\n","Requirement already satisfied: deepdiff<8.0,>=5.7.0 in /opt/conda/lib/python3.7/site-packages (from lightning) (6.3.0)\n","Requirement already satisfied: traitlets<7.0,>=5.3.0 in /opt/conda/lib/python3.7/site-packages (from lightning) (5.8.1)\n","Requirement already satisfied: fastapi<0.89.0 in /opt/conda/lib/python3.7/site-packages (from lightning) (0.88.0)\n","Requirement already satisfied: click<10.0 in /opt/conda/lib/python3.7/site-packages (from lightning) (8.1.3)\n","Requirement already satisfied: PyYAML<8.0 in /opt/conda/lib/python3.7/site-packages (from lightning) (6.0)\n","Requirement already satisfied: fsspec<2024.0,>=2022.5.0 in /opt/conda/lib/python3.7/site-packages (from lightning) (2023.1.0)\n","Requirement already satisfied: torchmetrics<2.0,>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from lightning) (0.11.4)\n","Requirement already satisfied: uvicorn<2.0 in /opt/conda/lib/python3.7/site-packages (from lightning) (0.20.0)\n","Requirement already satisfied: arrow<3.0,>=1.2.0 in /opt/conda/lib/python3.7/site-packages (from lightning) (1.2.3)\n","Requirement already satisfied: Jinja2<5.0 in /opt/conda/lib/python3.7/site-packages (from lightning) (3.1.2)\n","Requirement already satisfied: rich<15.0 in /opt/conda/lib/python3.7/site-packages (from lightning) (13.2.0)\n","Requirement already satisfied: websocket-client<3.0 in /opt/conda/lib/python3.7/site-packages (from lightning) (1.4.2)\n","Requirement already satisfied: inquirer<5.0,>=2.10.0 in /opt/conda/lib/python3.7/site-packages (from lightning) (2.10.1)\n","Requirement already satisfied: requests<4.0 in /opt/conda/lib/python3.7/site-packages (from lightning) (2.28.2)\n","Requirement already satisfied: websockets<12.0 in /opt/conda/lib/python3.7/site-packages (from lightning) (11.0)\n","Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from wandb) (59.8.0)\n","Requirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (0.4.0)\n","Requirement already satisfied: protobuf!=4.21.0,<5,>=3.12.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (3.20.3)\n","Requirement already satisfied: pathtools in /opt/conda/lib/python3.7/site-packages (from wandb) (0.1.2)\n","Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (3.1.30)\n","Requirement already satisfied: setproctitle in /opt/conda/lib/python3.7/site-packages (from wandb) (1.3.2)\n","Requirement already satisfied: appdirs>=1.4.3 in /opt/conda/lib/python3.7/site-packages (from wandb) (1.4.4)\n","Requirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (1.18.0)\n","Requirement already satisfied: python-dateutil>=2.7.0 in /opt/conda/lib/python3.7/site-packages (from arrow<3.0,>=1.2.0->lightning) (2.8.2)\n","Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.7/site-packages (from beautifulsoup4<6.0,>=4.8.0->lightning) (2.3.2.post1)\n","Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from click<10.0->lightning) (4.11.4)\n","Requirement already satisfied: pytz in /opt/conda/lib/python3.7/site-packages (from dateutils<2.0->lightning) (2023.3)\n","Requirement already satisfied: ordered-set<4.2.0,>=4.0.2 in /opt/conda/lib/python3.7/site-packages (from deepdiff<8.0,>=5.7.0->lightning) (4.1.0)\n","Requirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.7/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n","Requirement already satisfied: anyio<5,>=3.4.0 in /opt/conda/lib/python3.7/site-packages (from starlette<2.0->lightning) (3.6.2)\n","Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/conda/lib/python3.7/site-packages (from fsspec<2024.0,>=2022.5.0->lightning) (3.8.3)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.7/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.10)\n","Requirement already satisfied: readchar>=3.0.6 in /opt/conda/lib/python3.7/site-packages (from inquirer<5.0,>=2.10.0->lightning) (4.0.5)\n","Requirement already satisfied: blessed>=1.19.0 in /opt/conda/lib/python3.7/site-packages (from inquirer<5.0,>=2.10.0->lightning) (1.19.1)\n","Requirement already satisfied: python-editor>=1.0.4 in /opt/conda/lib/python3.7/site-packages (from inquirer<5.0,>=2.10.0->lightning) (1.0.4)\n","Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.7/site-packages (from Jinja2<5.0->lightning) (2.1.1)\n","Requirement already satisfied: pyjwt in /opt/conda/lib/python3.7/site-packages (from lightning-cloud>=0.5.27->lightning) (2.6.0)\n","Requirement already satisfied: python-multipart in /opt/conda/lib/python3.7/site-packages (from lightning-cloud>=0.5.27->lightning) (0.0.6)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<4.0->lightning) (3.4)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.7/site-packages (from requests<4.0->lightning) (2.1.1)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<4.0->lightning) (2022.12.7)\n","Requirement already satisfied: markdown-it-py<3.0.0,>=2.1.0 in /opt/conda/lib/python3.7/site-packages (from rich<15.0->lightning) (2.1.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.6.0 in /opt/conda/lib/python3.7/site-packages (from rich<15.0->lightning) (2.14.0)\n","Requirement already satisfied: itsdangerous<3.0.0,>=2.0.1 in /opt/conda/lib/python3.7/site-packages (from starsessions<2.0,>=1.2.1->lightning) (2.1.2)\n","Requirement already satisfied: h11>=0.8 in /opt/conda/lib/python3.7/site-packages (from uvicorn<2.0->lightning) (0.14.0)\n","Requirement already satisfied: asynctest==0.13.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec<2024.0,>=2022.5.0->lightning) (0.13.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec<2024.0,>=2022.5.0->lightning) (1.3.3)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.7/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec<2024.0,>=2022.5.0->lightning) (6.0.4)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec<2024.0,>=2022.5.0->lightning) (1.8.2)\n","Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.7/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec<2024.0,>=2022.5.0->lightning) (1.3.1)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.7/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec<2024.0,>=2022.5.0->lightning) (4.0.2)\n","Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec<2024.0,>=2022.5.0->lightning) (22.2.0)\n","Requirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.7/site-packages (from anyio<5,>=3.4.0->starlette<2.0->lightning) (1.3.0)\n","Requirement already satisfied: wcwidth>=0.1.4 in /opt/conda/lib/python3.7/site-packages (from blessed>=1.19.0->inquirer<5.0,>=2.10.0->lightning) (0.2.6)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.7/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.0)\n","Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->click<10.0->lightning) (3.11.0)\n","Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.7/site-packages (from markdown-it-py<3.0.0,>=2.1.0->rich<15.0->lightning) (0.1.2)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]}],"source":["!pip install lightning wandb"]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2023-05-16T06:34:51.405632Z","iopub.status.busy":"2023-05-16T06:34:51.404518Z","iopub.status.idle":"2023-05-16T06:34:52.413179Z","shell.execute_reply":"2023-05-16T06:34:52.411683Z","shell.execute_reply.started":"2023-05-16T06:34:51.405581Z"},"trusted":true},"outputs":[],"source":["!WANDB_API_KEY=8c780297be240a84f5c8b7d669cb158839b2637a"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2023-05-16T06:34:52.417245Z","iopub.status.busy":"2023-05-16T06:34:52.416363Z","iopub.status.idle":"2023-05-16T06:34:52.424292Z","shell.execute_reply":"2023-05-16T06:34:52.423163Z","shell.execute_reply.started":"2023-05-16T06:34:52.417197Z"},"trusted":true},"outputs":[],"source":["import pandas as pd\n","import torch \n","from torch import nn\n","from torch.utils.data import Dataset, DataLoader\n","import numpy as np\n","import lightning as pl\n","from pytorch_lightning.loggers import WandbLogger\n","import random\n","import wandb"]},{"cell_type":"code","execution_count":31,"metadata":{"execution":{"iopub.execute_input":"2023-05-16T06:34:52.430470Z","iopub.status.busy":"2023-05-16T06:34:52.429462Z","iopub.status.idle":"2023-05-16T06:34:55.047539Z","shell.execute_reply":"2023-05-16T06:34:55.046287Z","shell.execute_reply.started":"2023-05-16T06:34:52.430426Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcs20b075\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]}],"source":["!WANDB_API_KEY=8c780297be240a84f5c8b7d669cb158839b2637a wandb login"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-05-16T06:36:04.776933Z","iopub.status.busy":"2023-05-16T06:36:04.775718Z","iopub.status.idle":"2023-05-16T06:36:04.784344Z","shell.execute_reply":"2023-05-16T06:36:04.783193Z","shell.execute_reply.started":"2023-05-16T06:36:04.776878Z"},"trusted":true},"outputs":[],"source":["path = \"aksharantar_sampled/hin\"\n","train_path = path + \"/hin_train.csv\"\n","valid_path = path + \"/hin_valid.csv\"\n","test_path = path + \"/hin_test.csv\""]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-05-16T06:36:05.583197Z","iopub.status.busy":"2023-05-16T06:36:05.581978Z","iopub.status.idle":"2023-05-16T06:36:05.589915Z","shell.execute_reply":"2023-05-16T06:36:05.588474Z","shell.execute_reply.started":"2023-05-16T06:36:05.583147Z"},"trusted":true},"outputs":[],"source":["def get_data(path):\n","    dataset = pd.read_csv(path, header=None)\n","    dataset = dataset.values\n","    input = dataset[:, 0]\n","    output = dataset[:, 1]\n","    return input, output"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-05-16T06:36:06.239945Z","iopub.status.busy":"2023-05-16T06:36:06.239535Z","iopub.status.idle":"2023-05-16T06:36:06.337010Z","shell.execute_reply":"2023-05-16T06:36:06.335895Z","shell.execute_reply.started":"2023-05-16T06:36:06.239908Z"},"trusted":true},"outputs":[],"source":["train_dataset = get_data(train_path)\n","val_dataset = get_data(valid_path)"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-05-16T06:36:07.896068Z","iopub.status.busy":"2023-05-16T06:36:07.895677Z","iopub.status.idle":"2023-05-16T06:36:07.905845Z","shell.execute_reply":"2023-05-16T06:36:07.904490Z","shell.execute_reply.started":"2023-05-16T06:36:07.896033Z"},"trusted":true},"outputs":[],"source":["def convert_word_to_tensor(word, lang):\n","    lang_to_int = {'SOS': 0, 'EOS': 1, 'PAD': 2}\n","    if lang == 'eng':\n","        lang_to_int.update({chr(i): i-94 for i in range(97, 123)})\n","    elif lang == 'hin':\n","        lang_to_int.update({chr(i): i-2300 for i in range(2304, 2432)})\n","    \n","    a = [lang_to_int['SOS']]\n","\n","    for i in word:\n","        a.append(lang_to_int[i])\n","\n","    a.append(lang_to_int['EOS'])\n","    if len(a) < 24:\n","        a.extend([lang_to_int['PAD']]*(24-len(a)))\n","    \n","    return torch.tensor(a)"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-05-16T06:36:08.647884Z","iopub.status.busy":"2023-05-16T06:36:08.647495Z","iopub.status.idle":"2023-05-16T06:36:08.659827Z","shell.execute_reply":"2023-05-16T06:36:08.658704Z","shell.execute_reply.started":"2023-05-16T06:36:08.647849Z"},"trusted":true},"outputs":[],"source":["class AksharantarDataset(Dataset):\n","    def __init__(self, dataset):\n","        super().__init__()\n","        self.dataset = dataset\n","        self.input = dataset[0]\n","        self.output = dataset[1]\n","        mask = np.array([len(elem) < 21 for elem in self.input]) & np.array([len(elem) < 21 for elem in self.output])\n","        self.input = self.input[mask]\n","        self.output = self.output[mask]\n","        self.len = len(self.input)\n","    \n","    def __getitem__(self, index):\n","        return convert_word_to_tensor(self.input[index], 'eng'), convert_word_to_tensor(self.output[index], 'hin')\n","    \n","    def __len__(self):\n","        return self.len"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-05-16T06:36:09.072136Z","iopub.status.busy":"2023-05-16T06:36:09.071756Z","iopub.status.idle":"2023-05-16T06:36:09.080077Z","shell.execute_reply":"2023-05-16T06:36:09.078868Z","shell.execute_reply.started":"2023-05-16T06:36:09.072103Z"},"trusted":true},"outputs":[],"source":["class CustomDataModule(pl.LightningDataModule):\n","    def __init__(self, dataset, val_dataset, batch_size=32):\n","        super().__init__()\n","        self.dataset = train_dataset\n","        self.val_dataset = val_dataset\n","        self.batch_size = batch_size\n","\n","    def train_dataloader(self):\n","        dataset = AksharantarDataset(self.dataset)\n","        return DataLoader(dataset, batch_size=self.batch_size, num_workers=2)\n","    def val_dataloader(self):\n","        dataset = AksharantarDataset(self.val_dataset)\n","        return DataLoader(dataset, batch_size=self.batch_size, num_workers=2)"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-05-16T06:36:09.739374Z","iopub.status.busy":"2023-05-16T06:36:09.738298Z","iopub.status.idle":"2023-05-16T06:36:09.753016Z","shell.execute_reply":"2023-05-16T06:36:09.751525Z","shell.execute_reply.started":"2023-05-16T06:36:09.739322Z"},"trusted":true},"outputs":[],"source":["train_loader = CustomDataModule(train_dataset, val_dataset, 32)\n","# val_loader = CustomDataModule(val_dataset, 32)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Encoder model"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-05-16T06:36:11.018191Z","iopub.status.busy":"2023-05-16T06:36:11.017766Z","iopub.status.idle":"2023-05-16T06:36:11.032010Z","shell.execute_reply":"2023-05-16T06:36:11.030663Z","shell.execute_reply.started":"2023-05-16T06:36:11.018152Z"},"trusted":true},"outputs":[],"source":["class Encoder(pl.LightningModule):\n","    def __init__(self, input_size, hidden_size, cell_type, num_layers=1, dropout=0, bidirectional=False):\n","        super().__init__()\n","        self.hidden_size = hidden_size\n","        self.embedding = nn.Embedding(input_size, hidden_size)\n","        self.cell_type = cell_type\n","        if cell_type == 'LSTM':\n","            self.rnn = nn.LSTM\n","        elif cell_type == 'GRU':\n","            self.rnn = nn.GRU\n","        else:\n","            self.rnn = nn.RNN\n","        self.direction = 2 if bidirectional else 1\n","        self.first_cell = self.rnn(hidden_size, hidden_size, bidirectional=bidirectional, batch_first=True)\n","        self.rnns = nn.ModuleList([self.rnn(hidden_size*self.direction, hidden_size, bidirectional=bidirectional, batch_first=True)]*(num_layers-1))\n","        self.num_layers = num_layers\n","\n","    def forward(self, input, hidden):\n","        embedded = self.embedding(input)\n","        # embedded = embedded.view(1, 1, -1)\n","        output = embedded\n","        output, hidden = self.first_cell(output, hidden)\n","        for i in range(self.num_layers-1):\n","            output, hidden = self.rnns[i](output, hidden)\n","        return output, hidden\n","\n","    def init_hidden(self):\n","        if self.cell_type == 'LSTM':\n","            return torch.zeros(self.direction, self.hidden_size), torch.zeros(self.direction, self.hidden_size)\n","        return torch.zeros(self.direction, self.hidden_size, device=self.device)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Decoder"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-05-16T06:36:11.637653Z","iopub.status.busy":"2023-05-16T06:36:11.637209Z","iopub.status.idle":"2023-05-16T06:36:11.652484Z","shell.execute_reply":"2023-05-16T06:36:11.651078Z","shell.execute_reply.started":"2023-05-16T06:36:11.637615Z"},"trusted":true},"outputs":[],"source":["class Decoder(pl.LightningModule):\n","    def __init__(self, output_size, hidden_size, cell_type, num_layers=1, bidirectional=False, dropout=0):\n","        super().__init__()\n","        self.hidden_size = hidden_size\n","        self.embedding = nn.Embedding(output_size, hidden_size)\n","        if cell_type == 'LSTM':\n","            self.cell_type = nn.LSTM\n","        elif cell_type == 'GRU':\n","            self.cell_type = nn.GRU\n","        else:\n","            self.cell_type = nn.RNN\n","        self.first_cell = self.cell_type(hidden_size, hidden_size, bidirectional=bidirectional, batch_first=True)\n","        self.direction = 2 if bidirectional else 1\n","        self.rnns= nn.ModuleList([self.cell_type(hidden_size*self.direction, hidden_size, bidirectional=bidirectional, batch_first=True)]*(num_layers-1))\n","        self.out = nn.Linear(hidden_size*self.direction, output_size)\n","        self.softmax = nn.LogSoftmax(dim=-1)\n","        self.num_layers = num_layers\n","\n","    def forward(self, input, hidden):\n","        output = self.embedding(input)\n","        output = nn.functional.relu(output)\n","        output, hidden = self.first_cell(output, hidden)\n","        for i in range(self.num_layers-1):\n","            output, hidden = self.rnns[i](output, hidden)\n","        linear_output = self.out(output)\n","        output = self.softmax(self.out(output))\n","        if output.shape[0] == 1:\n","            output = output.squeeze(0)\n","        return output, hidden"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Seq2seq model"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2023-05-16T06:46:55.482586Z","iopub.status.busy":"2023-05-16T06:46:55.482120Z","iopub.status.idle":"2023-05-16T06:46:55.549975Z","shell.execute_reply":"2023-05-16T06:46:55.548793Z","shell.execute_reply.started":"2023-05-16T06:46:55.482547Z"},"trusted":true},"outputs":[],"source":["class Seq2seq(pl.LightningModule):\n","    def __init__(self, encoder, decoder):\n","        super().__init__()\n","        self.encoder = encoder.to(self.device)\n","        self.decoder = decoder.to(self.device)\n","\n","    def forward(self, input):\n","        \n","        self.encoder = self.encoder.to(self.device)\n","        self.decoder = self.decoder.to(self.device)\n","        \n","        batched = True if len(input.shape) > 1 else False\n","        if not batched:\n","            input = input.unsqueeze(0)\n","            target = target.unsqueeze(0)\n","        input = input.to(self.device)\n","        target = target.to(self.device)\n","        batch_size = input.shape[0]\n","        input_length = input.shape[1]\n","        target_length = target.shape[1]\n","\n","        encoder_hidden = None\n","        encoder_hidden_outputs = torch.zeros(input_length, self.encoder.direction, batch_size, self.encoder.hidden_size, device=self.device)\n","        encoder_output_gate = torch.zeros(input_length, self.encoder.direction, batch_size, self.encoder.hidden_size, device=self.device)\n","        if self.encoder.cell_type == 'LSTM':\n","            a, b = [torch.zeros(self.encoder.direction, batch_size, self.encoder.hidden_size)]*2\n","            encoder_hidden = a.to(self.device), b.to(self.device)\n","        else:\n","            encoder_hidden = torch.zeros(self.encoder.direction, batch_size, self.encoder.hidden_size).to(self.device)\n","        for i in range(input_length):\n","            # print(input[:, i].shape, encoder_hidden.shape)\n","            _, encoder_hidden_out = self.encoder(input[:, i].unsqueeze(1), encoder_hidden)\n","            if self.encoder.cell_type == 'LSTM':\n","                encoder_hidden_outputs[i] = encoder_hidden_out[0]\n","                encoder_output_gate[i] = encoder_hidden_out[1]\n","            else:\n","                encoder_hidden_outputs[i] = encoder_hidden_out\n","        if self.encoder.cell_type == 'LSTM':\n","            decoder_hidden = encoder_hidden_outputs[-1], encoder_output_gate[-1]\n","        else:\n","            decoder_hidden = encoder_hidden_outputs[-1]\n","        decoder_input = target[:, 0].unsqueeze(1)\n","        for j in range(target_length):\n","            decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden)\n","            decoder_input = decoder_output.argmax(dim=-1)\n","        output_sequence = torch.tensor(output_sequence, device=self.device)\n","        if not batched:\n","            output_sequence = output_sequence.squeeze(0)\n","        return output_sequence\n","        \n","    def training_step(self, batch, batch_idx):\n","        input, target = batch\n","        \n","        self.encoder = self.encoder.to(self.device)\n","        self.decoder = self.decoder.to(self.device)\n","        \n","        batched = True if len(input.shape) > 1 else False\n","        if not batched:\n","            input = input.unsqueeze(0)\n","            target = target.unsqueeze(0)\n","        input = input.to(self.device)\n","        target = target.to(self.device)\n","        batch_size = input.shape[0]\n","        input_length = input.shape[1]\n","        target_length = target.shape[1]\n","\n","        encoder_hidden = None\n","        encoder_hidden_outputs = torch.zeros(input_length, self.encoder.direction, batch_size, self.encoder.hidden_size, device=self.device)\n","        encoder_output_gate = torch.zeros(input_length, self.encoder.direction, batch_size, self.encoder.hidden_size, device=self.device)\n","        if self.encoder.cell_type == 'LSTM':\n","            a, b = [torch.zeros(self.encoder.direction, batch_size, self.encoder.hidden_size)]*2\n","            encoder_hidden = a.to(self.device), b.to(self.device)\n","        else:\n","            encoder_hidden = torch.zeros(self.encoder.direction, batch_size, self.encoder.hidden_size).to(self.device)\n","        for i in range(input_length):\n","            # print(input[:, i].shape, encoder_hidden.shape)\n","            _, encoder_hidden_out = self.encoder(input[:, i].unsqueeze(1), encoder_hidden)\n","            if self.encoder.cell_type == 'LSTM':\n","                encoder_hidden_outputs[i] = encoder_hidden_out[0]\n","                encoder_output_gate[i] = encoder_hidden_out[1]\n","            else:\n","                encoder_hidden_outputs[i] = encoder_hidden_out\n","        loss = 0\n","        correct_words = 0\n","        if self.encoder.cell_type == 'LSTM':\n","            decoder_hidden = encoder_hidden_outputs[-1], encoder_output_gate[-1]\n","        else:\n","            decoder_hidden = encoder_hidden_outputs[-1]\n","        if random.random() < 0.5: \n","            decoder_input = target[:, 0].unsqueeze(1)\n","            correct = None\n","            for j in range(target_length):\n","                decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden)\n","                squeezed_output = decoder_output.squeeze(1)\n","                for i in range(batch_size):\n","                    loss += nn.functional.nll_loss(squeezed_output[i], target[i, j])\n","                decoder_input = target[:, j].unsqueeze(1)\n","                if correct is None:\n","                    correct = decoder_output.argmax(dim=-1) == target[:, j]\n","                else:\n","                    correct = (decoder_output.argmax(dim=-1) == target[:, j]) & correct\n","            correct_words = correct.sum()\n","\n","        else:\n","            decoder_input = target[:, 0].unsqueeze(1)\n","            correct = None\n","            for j in range(target_length):\n","                decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden)\n","                squeezed_output = decoder_output.squeeze(1)\n","                for i in range(batch_size):\n","                    loss += nn.functional.nll_loss(squeezed_output[i], target[i, j])\n","                decoder_input = decoder_output.argmax(dim=-1)\n","                if correct is None:\n","                    correct = decoder_input == target[:, j]\n","                else:\n","                    correct = (decoder_input == target[:, j]) & correct\n","            correct_words = correct.sum()\n","\n","        # print(correct_words, batch_size, correct_words/batch_size)\n","        reported_loss = loss / (batch_size * target_length)\n","        self.log('train_loss', reported_loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n","        self.log('train_acc', correct_words/batch_size, on_step=True, on_epoch=True, logger=True, prog_bar=True)\n","        return loss\n","    def validation_step(self, batch, batch_idx):\n","        input, target = batch\n","        \n","        self.encoder = self.encoder.to(self.device)\n","        self.decoder = self.decoder.to(self.device)\n","        \n","        batched = True if len(input.shape) > 1 else False\n","        if not batched:\n","            input = input.unsqueeze(0)\n","            target = target.unsqueeze(0)\n","        input = input.to(self.device)\n","        target = target.to(self.device)\n","        batch_size = input.shape[0]\n","        input_length = input.shape[1]\n","        target_length = target.shape[1]\n","\n","        encoder_hidden = None\n","        encoder_hidden_outputs = torch.zeros(input_length, self.encoder.direction, batch_size, self.encoder.hidden_size, device=self.device)\n","        encoder_output_gate = torch.zeros(input_length, self.encoder.direction, batch_size, self.encoder.hidden_size, device=self.device)\n","        if self.encoder.cell_type == 'LSTM':\n","            a, b = [torch.zeros(self.encoder.direction, batch_size, self.encoder.hidden_size)]*2\n","            encoder_hidden = a.to(self.device), b.to(self.device)\n","        else:\n","            encoder_hidden = torch.zeros(self.encoder.direction, batch_size, self.encoder.hidden_size).to(self.device)\n","        for i in range(input_length):\n","            # print(input[:, i].shape, encoder_hidden.shape)\n","            _, encoder_hidden_out = self.encoder(input[:, i].unsqueeze(1), encoder_hidden)\n","            if self.encoder.cell_type == 'LSTM':\n","                encoder_hidden_outputs[i] = encoder_hidden_out[0]\n","                encoder_output_gate[i] = encoder_hidden_out[1]\n","            else:\n","                encoder_hidden_outputs[i] = encoder_hidden_out\n","        loss = 0\n","        correct_words = 0\n","        if self.encoder.cell_type == 'LSTM':\n","            decoder_hidden = encoder_hidden_outputs[-1], encoder_output_gate[-1]\n","        else:\n","            decoder_hidden = encoder_hidden_outputs[-1]\n","        decoder_input = target[:, 0].unsqueeze(1)\n","        correct = None\n","        for j in range(target_length):\n","            decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden)\n","            squeezed_output = decoder_output.squeeze(1)\n","            for i in range(batch_size):\n","                loss += nn.functional.nll_loss(squeezed_output[i], target[i, j])\n","            decoder_input = decoder_output.argmax(dim=-1)\n","            if correct is None:\n","                correct = decoder_input == target[:, j]\n","            else:\n","                correct = (decoder_input == target[:, j]) & correct\n","        correct_words = correct.sum()\n","\n","        # for i in range(batch_size):\n","        #     if self.encoder.cell_type == 'LSTM':\n","        #         decoder_hidden = encoder_hidden_outputs[i].view(self.decoder.direction, -1), encoder_output_gate[i].view(self.decoder.direction, -1)\n","        #     else:\n","        #         decoder_hidden = encoder_hidden_outputs[i].view(self.decoder.direction, -1)\n","        #     decoder_input = target[i, 0].unsqueeze(0)\n","        #     correct = True\n","        #     for j in range(target_length):\n","        #         decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden)\n","        #         loss += nn.functional.nll_loss(decoder_output, target[i, j])\n","        #         decoder_input = torch.tensor([decoder_output.argmax().item()]).to(self.device)\n","        #         if correct and target[i, j]!= decoder_output.argmax().item():\n","        #             correct = False\n","        #     if correct:\n","        #         correct_words  += 1\n","        reported_loss = loss / (batch_size * target_length)\n","        self.log('val_loss', reported_loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n","        self.log('val_acc', correct_words/batch_size, on_epoch=True, prog_bar=True, logger=True)\n","        return loss\n","    def configure_optimizers(self):\n","        return torch.optim.Adam(self.parameters(), lr=0.001)"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2023-05-16T06:46:55.861327Z","iopub.status.busy":"2023-05-16T06:46:55.860979Z","iopub.status.idle":"2023-05-16T06:46:55.882562Z","shell.execute_reply":"2023-05-16T06:46:55.881535Z","shell.execute_reply.started":"2023-05-16T06:46:55.861294Z"},"trusted":true},"outputs":[],"source":["encoder = Encoder(30, 64, cell_type=\"LSTM\", num_layers=2, bidirectional=True, dropout=0.1)\n","decoder = Decoder(150, 64, cell_type=\"LSTM\", num_layers=3, bidirectional=True)\n","model = Seq2seq(encoder, decoder)"]},{"cell_type":"code","execution_count":66,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["GPU available: False, used: False\n","TPU available: False, using: 0 TPU cores\n","IPU available: False, using: 0 IPUs\n","HPU available: False, using: 0 HPUs\n","\n","  | Name    | Type    | Params\n","------------------------------------\n","0 | encoder | Encoder | 167 K \n","1 | decoder | Decoder | 194 K \n","------------------------------------\n","362 K     Trainable params\n","0         Non-trainable params\n","362 K     Total params\n","1.451     Total estimated model params size (MB)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 0:   0%|          | 0/1599 [13:38<?, ?it/s] 4.61it/s, v_num=186, train_loss_step=1.220, train_acc_step=0.000]\n","Epoch 0:   0%|          | 2/1599 [12:46<170:02:08, 383.30s/it, v_num=175, train_loss_step=4.800, train_acc_step=0.000]\n","Epoch 0:   0%|          | 2/1599 [12:14<162:51:33, 367.12s/it, v_num=176, train_loss_step=4.780, train_acc_step=0.000]\n","Epoch 0:   0%|          | 0/1599 [09:47<?, ?it/s]\n","Epoch 0:   0%|          | 1/1599 [08:56<238:04:40, 536.35s/it, v_num=178, train_loss_step=4.980, train_acc_step=0.000]\n","Epoch 0:   0%|          | 0/1599 [05:13<?, ?it/s]\n","Epoch 0:   0%|          | 0/1599 [04:55<?, ?it/s]\n","Epoch 0: 100%|██████████| 1599/1599 [06:32<00:00,  4.07it/s, v_num=186, train_loss_step=1.060, train_acc_step=0.000, val_loss_step=1.150, val_loss_epoch=1.200, val_acc=0.000, train_loss_epoch=1.310, train_acc_epoch=0.000]"]},{"name":"stderr","output_type":"stream","text":["`Trainer.fit` stopped: `max_epochs=1` reached.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 0: 100%|██████████| 1599/1599 [06:32<00:00,  4.07it/s, v_num=186, train_loss_step=1.060, train_acc_step=0.000, val_loss_step=1.150, val_loss_epoch=1.200, val_acc=0.000, train_loss_epoch=1.310, train_acc_epoch=0.000]\n"]}],"source":["trainer = pl.Trainer(max_epochs=1)\n","trainer.fit(model, train_loader)"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2023-05-11T20:24:54.863147Z","iopub.status.busy":"2023-05-11T20:24:54.862722Z","iopub.status.idle":"2023-05-11T20:24:54.871728Z","shell.execute_reply":"2023-05-11T20:24:54.870454Z","shell.execute_reply.started":"2023-05-11T20:24:54.863108Z"},"trusted":true},"outputs":[],"source":["def convert_tensor_to_word(tensor, lang):\n","    int_to_lang = {0: 'SOS', 1: 'EOS', 2: 'PAD'}\n","    if lang == 'eng':\n","        int_to_lang.update({i-94: chr(i) for i in range(97, 123)})\n","    elif lang == 'hin':\n","        int_to_lang.update({i-2300: chr(i) for i in range(2304, 2432)})\n","    \n","    word = ''\n","    for i in tensor:\n","        word += int_to_lang[i.item()]\n","    return word"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[{"data":{"text/plain":["'SOSSOSघरेलूEOSPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPAD'"]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["convert_tensor_to_word(model(convert_word_to_tensor('gharelu', 'eng')), 'hin')"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2023-05-11T20:24:55.521250Z","iopub.status.busy":"2023-05-11T20:24:55.519868Z","iopub.status.idle":"2023-05-11T20:24:55.529506Z","shell.execute_reply":"2023-05-11T20:24:55.528393Z","shell.execute_reply.started":"2023-05-11T20:24:55.521200Z"},"trusted":true},"outputs":[],"source":["sweep_config = {\n","    'method': 'bayes',\n","    'metric': {\n","        'name': 'val_loss',\n","        'goal': 'minimize'\n","    },\n","    'parameters': {\n","        'hidden_size': {\n","            'values': [64, 128, 256],\n","        },\n","        'encoder_num_layers': {\n","            'values': [1, 2, 3],\n","        },\n","        'decoder_num_layers': {\n","            'values': [1, 2, 3],\n","        },\n","        'bidirectional': {\n","            'values': [True, False],\n","        },\n","        'cell_type': {\n","            'values': ['LSTM', 'GRU'],\n","        },\n","    }\n","}"]},{"cell_type":"code","execution_count":31,"metadata":{"execution":{"iopub.execute_input":"2023-05-11T20:24:56.814281Z","iopub.status.busy":"2023-05-11T20:24:56.812905Z","iopub.status.idle":"2023-05-11T20:24:56.823454Z","shell.execute_reply":"2023-05-11T20:24:56.822264Z","shell.execute_reply.started":"2023-05-11T20:24:56.814223Z"},"trusted":true},"outputs":[],"source":["def sweep_fn():\n","    wandb.init()\n","    config = wandb.config\n","    dropout_val = 0\n","    encoder=Encoder(30, config.hidden_size, config.cell_type, num_layers=config.encoder_num_layers, bidirectional=config.bidirectional)\n","    decoder = Decoder(150, config.hidden_size, config.cell_type, num_layers=config.decoder_num_layers, bidirectional=config.bidirectional)\n","    model = Seq2seq(encoder, decoder)\n","    logger = WandbLogger(project='CS6910 Assignment 3', entity='cs20b075')\n","    trainer = pl.Trainer(max_epochs=5, precision=16, logger=logger)\n","    trainer.fit(model, train_loader)"]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2023-05-11T20:24:59.204864Z","iopub.status.busy":"2023-05-11T20:24:59.204190Z","iopub.status.idle":"2023-05-11T20:24:59.305703Z","shell.execute_reply":"2023-05-11T20:24:59.304455Z","shell.execute_reply.started":"2023-05-11T20:24:59.204820Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcs20b075\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/sooraj/.netrc\n"]},{"data":{"text/plain":["True"]},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["wandb.login(key=\"8c780297be240a84f5c8b7d669cb158839b2637a\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-11T20:25:02.475513Z","iopub.status.busy":"2023-05-11T20:25:02.474451Z","iopub.status.idle":"2023-05-11T20:29:19.350116Z","shell.execute_reply":"2023-05-11T20:29:19.346270Z","shell.execute_reply.started":"2023-05-11T20:25:02.475451Z"},"trusted":true},"outputs":[],"source":["sweep_id = wandb.sweep(sweep=sweep_config, project=\"CS6910 Assignment 3\")\n","wandb.agent(sweep_id=sweep_id, function=sweep_fn, count=10)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["wandb.agent(sweep_id=\"1aw4o8ik\", function=sweep_fn, count=10, project=\"CS6910 Assignment 3\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-11T20:19:23.845801Z","iopub.status.busy":"2023-05-11T20:19:23.841384Z","iopub.status.idle":"2023-05-11T20:19:23.852667Z","shell.execute_reply":"2023-05-11T20:19:23.850824Z","shell.execute_reply.started":"2023-05-11T20:19:23.845753Z"},"trusted":true},"outputs":[],"source":["wandb.finish()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Adding attention to the Seq2Seq model"]},{"cell_type":"code","execution_count":97,"metadata":{},"outputs":[],"source":["class AttnDecoder(pl.LightningModule):\n","    def __init__(self, output_size, hidden_size, attention_size, cell_type, num_layers=1, bidirectional=False, dropout=0):\n","        super().__init__()\n","        self.hidden_size = hidden_size\n","        self.embedding = nn.Embedding(output_size, hidden_size)\n","        if cell_type == 'LSTM':\n","            self.cell_type = nn.LSTM\n","        elif cell_type == 'GRU':\n","            self.cell_type = nn.GRU\n","        else:\n","            self.cell_type = nn.RNN\n","        self.first_cell = self.cell_type(hidden_size, hidden_size, bidirectional=bidirectional, batch_first=True)\n","        self.direction = 2 if bidirectional else 1\n","        self.rnns= nn.ModuleList([self.cell_type(hidden_size*self.direction, hidden_size, bidirectional=bidirectional, batch_first=True)]*(num_layers-1))\n","        self.out = nn.Linear(hidden_size*self.direction, output_size)\n","        self.softmax = nn.LogSoftmax(dim=-1)\n","        self.num_layers = num_layers\n","\n","        self.Uattn = nn.Linear(hidden_size*self.direction, attention_size)\n","        self.Wattn = nn.Linear(hidden_size*self.direction, attention_size)\n","        self.Vattn = nn.Linear(attention_size, 1)\n","\n","        self.attn_combine = nn.Linear(hidden_size + hidden_size*self.direction, hidden_size)\n","\n","    def forward(self, input, hidden, encoder_outputs):\n","        # print(\"Am in the decoder\")\n","        # print(\"Printing the shapes of everything here:\")\n","        # print(\"Input shape:\", input.shape)\n","        # print(\"Hidden shape:\", hidden.shape)\n","        # print(\"Encoder outputs shape:\", encoder_outputs.shape)\n","        encoder_outputs_flat = encoder_outputs.transpose(1, 2).flatten(2)\n","        hidden_flat = None\n","        if self.cell_type == nn.LSTM:\n","            hidden_flat = hidden[0].transpose(0, 1).flatten(1)\n","        else:\n","            hidden_flat = hidden.transpose(0, 1).flatten(1)\n","        # print(\"Flattened shapes:\", encoder_outputs_flat.shape, hidden_flat.shape)\n","        # print(\"HIdden shapes:\", self.Uattn.shape, self.Wattn.shape, self.Vattn.shape)\n","        encoder_part = self.Uattn(encoder_outputs_flat)\n","        # print(\"got past Uattn\", encoder_outputs_flat.shape, encoder_part.shape)\n","        decoder_part = self.Wattn(hidden_flat.repeat(encoder_outputs.shape[0], 1, 1))\n","        # print(\"got past Wattn\", decoder_part.shape)\n","        # ejt = torch.tanh(self.Uattn(encoder_outputs) + self.Wattn(hidden[0].repeat(1, encoder_outputs.shape[1], 1)))\n","        ejt = torch.tanh(encoder_part + decoder_part)\n","        at = self.Vattn(ejt).squeeze(-1)\n","        # print(at.shape)\n","        at = nn.functional.softmax(at, dim=0)\n","        at = at.transpose(0, 1).unsqueeze(1)\n","        # print(\"Attention\", at.shape)\n","        encoder_outputs_flat = encoder_outputs_flat.transpose(0, 1)\n","        # print(\"Encoder outputs flat\", encoder_outputs_flat.shape)\n","        context = torch.bmm(at, encoder_outputs_flat).squeeze(1)\n","        # print(\"Context\", context.shape)\n","        \n","        output = self.embedding(input)\n","        # print(\"Output\", output.shape)\n","        output = nn.functional.relu(output)\n","        output = torch.cat((output.squeeze(1), context), dim=-1).unsqueeze(1)\n","        output = self.attn_combine(output)\n","        output, hidden = self.first_cell(output, hidden)\n","        for i in range(self.num_layers-1):\n","            output, hidden = self.rnns[i](output, hidden)\n","        linear_output = self.out(output)\n","        output = self.softmax(self.out(output))\n","        if output.shape[0] == 1:\n","            output = output.squeeze(0)\n","        return output, hidden"]},{"cell_type":"code","execution_count":98,"metadata":{},"outputs":[],"source":["class AttnSeq2seq(pl.LightningModule):\n","    def __init__(self, encoder, decoder):\n","        super().__init__()\n","        self.encoder = encoder.to(self.device)\n","        self.decoder = decoder.to(self.device)\n","\n","    def forward(self, input):\n","        \n","        self.encoder = self.encoder.to(self.device)\n","        self.decoder = self.decoder.to(self.device)\n","        \n","        batched = True if len(input.shape) > 1 else False\n","        if not batched:\n","            input = input.unsqueeze(0)\n","            target = target.unsqueeze(0)\n","        input = input.to(self.device)\n","        target = target.to(self.device)\n","        batch_size = input.shape[0]\n","        input_length = input.shape[1]\n","        target_length = target.shape[1]\n","\n","        encoder_hidden = None\n","        encoder_hidden_outputs = torch.zeros(input_length, self.encoder.direction, batch_size, self.encoder.hidden_size, device=self.device)\n","        encoder_output_gate = torch.zeros(input_length, self.encoder.direction, batch_size, self.encoder.hidden_size, device=self.device)\n","        if self.encoder.cell_type == 'LSTM':\n","            a, b = [torch.zeros(self.encoder.direction, batch_size, self.encoder.hidden_size)]*2\n","            encoder_hidden = a.to(self.device), b.to(self.device)\n","        else:\n","            encoder_hidden = torch.zeros(self.encoder.direction, batch_size, self.encoder.hidden_size).to(self.device)\n","        for i in range(input_length):\n","            # print(input[:, i].shape, encoder_hidden.shape)\n","            _, encoder_hidden_out = self.encoder(input[:, i].unsqueeze(1), encoder_hidden)\n","            if self.encoder.cell_type == 'LSTM':\n","                encoder_hidden_outputs[i] = encoder_hidden_out[0]\n","                encoder_output_gate[i] = encoder_hidden_out[1]\n","            else:\n","                encoder_hidden_outputs[i] = encoder_hidden_out\n","        if self.encoder.cell_type == 'LSTM':\n","            decoder_hidden = encoder_hidden_outputs[-1], encoder_output_gate[-1]\n","        else:\n","            decoder_hidden = encoder_hidden_outputs[-1]\n","        decoder_input = target[:, 0].unsqueeze(1)\n","        for j in range(target_length):\n","            decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden, encoder_hidden_outputs)\n","            decoder_input = decoder_output.argmax(dim=-1)\n","        output_sequence = torch.tensor(output_sequence, device=self.device)\n","        if not batched:\n","            output_sequence = output_sequence.squeeze(0)\n","        return output_sequence\n","        \n","    def training_step(self, batch, batch_idx):\n","        input, target = batch\n","        \n","        self.encoder = self.encoder.to(self.device)\n","        self.decoder = self.decoder.to(self.device)\n","        \n","        batched = True if len(input.shape) > 1 else False\n","        if not batched:\n","            input = input.unsqueeze(0)\n","            target = target.unsqueeze(0)\n","        input = input.to(self.device)\n","        target = target.to(self.device)\n","        batch_size = input.shape[0]\n","        input_length = input.shape[1]\n","        target_length = target.shape[1]\n","\n","        encoder_hidden = None\n","        encoder_hidden_outputs = torch.zeros(input_length, self.encoder.direction, batch_size, self.encoder.hidden_size, device=self.device)\n","        encoder_output_gate = torch.zeros(input_length, self.encoder.direction, batch_size, self.encoder.hidden_size, device=self.device)\n","        if self.encoder.cell_type == 'LSTM':\n","            a, b = [torch.zeros(self.encoder.direction, batch_size, self.encoder.hidden_size)]*2\n","            encoder_hidden = a.to(self.device), b.to(self.device)\n","        else:\n","            encoder_hidden = torch.zeros(self.encoder.direction, batch_size, self.encoder.hidden_size).to(self.device)\n","        for i in range(input_length):\n","            # print(input[:, i].shape, encoder_hidden.shape)\n","            _, encoder_hidden_out = self.encoder(input[:, i].unsqueeze(1), encoder_hidden)\n","            if self.encoder.cell_type == 'LSTM':\n","                encoder_hidden_outputs[i] = encoder_hidden_out[0]\n","                encoder_output_gate[i] = encoder_hidden_out[1]\n","            else:\n","                encoder_hidden_outputs[i] = encoder_hidden_out\n","        loss = 0\n","        correct_words = 0\n","        if self.encoder.cell_type == 'LSTM':\n","            decoder_hidden = encoder_hidden_outputs[-1], encoder_output_gate[-1]\n","        else:\n","            decoder_hidden = encoder_hidden_outputs[-1]\n","        if random.random() < 0.5: \n","            decoder_input = target[:, 0].unsqueeze(1)\n","            correct = None\n","            for j in range(target_length):\n","                decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden, encoder_hidden_outputs)\n","                squeezed_output = decoder_output.squeeze(1)\n","                for i in range(batch_size):\n","                    loss += nn.functional.nll_loss(squeezed_output[i], target[i, j])\n","                decoder_input = target[:, j].unsqueeze(1)\n","                if correct is None:\n","                    correct = decoder_output.argmax(dim=-1) == target[:, j]\n","                else:\n","                    correct = (decoder_output.argmax(dim=-1) == target[:, j]) & correct\n","            correct_words = correct.sum()\n","\n","        else:\n","            decoder_input = target[:, 0].unsqueeze(1)\n","            correct = None\n","            for j in range(target_length):\n","                decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden, encoder_hidden_outputs)\n","                squeezed_output = decoder_output.squeeze(1)\n","                for i in range(batch_size):\n","                    loss += nn.functional.nll_loss(squeezed_output[i], target[i, j])\n","                decoder_input = decoder_output.argmax(dim=-1)\n","                if correct is None:\n","                    correct = decoder_input == target[:, j]\n","                else:\n","                    correct = (decoder_input == target[:, j]) & correct\n","            correct_words = correct.sum()\n","\n","        # print(correct_words, batch_size, correct_words/batch_size)\n","        reported_loss = loss / (batch_size * target_length)\n","        self.log('train_loss', reported_loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n","        self.log('train_acc', correct_words/batch_size, on_step=True, on_epoch=True, logger=True, prog_bar=True)\n","        return loss\n","    def validation_step(self, batch, batch_idx):\n","        input, target = batch\n","        \n","        self.encoder = self.encoder.to(self.device)\n","        self.decoder = self.decoder.to(self.device)\n","        \n","        batched = True if len(input.shape) > 1 else False\n","        if not batched:\n","            input = input.unsqueeze(0)\n","            target = target.unsqueeze(0)\n","        input = input.to(self.device)\n","        target = target.to(self.device)\n","        batch_size = input.shape[0]\n","        input_length = input.shape[1]\n","        target_length = target.shape[1]\n","\n","        encoder_hidden = None\n","        encoder_hidden_outputs = torch.zeros(input_length, self.encoder.direction, batch_size, self.encoder.hidden_size, device=self.device)\n","        encoder_output_gate = torch.zeros(input_length, self.encoder.direction, batch_size, self.encoder.hidden_size, device=self.device)\n","        if self.encoder.cell_type == 'LSTM':\n","            a, b = [torch.zeros(self.encoder.direction, batch_size, self.encoder.hidden_size)]*2\n","            encoder_hidden = a.to(self.device), b.to(self.device)\n","        else:\n","            encoder_hidden = torch.zeros(self.encoder.direction, batch_size, self.encoder.hidden_size).to(self.device)\n","        for i in range(input_length):\n","            # print(input[:, i].shape, encoder_hidden.shape)\n","            _, encoder_hidden_out = self.encoder(input[:, i].unsqueeze(1), encoder_hidden)\n","            if self.encoder.cell_type == 'LSTM':\n","                encoder_hidden_outputs[i] = encoder_hidden_out[0]\n","                encoder_output_gate[i] = encoder_hidden_out[1]\n","            else:\n","                encoder_hidden_outputs[i] = encoder_hidden_out\n","        loss = 0\n","        correct_words = 0\n","        if self.encoder.cell_type == 'LSTM':\n","            decoder_hidden = encoder_hidden_outputs[-1], encoder_output_gate[-1]\n","        else:\n","            decoder_hidden = encoder_hidden_outputs[-1]\n","        decoder_input = target[:, 0].unsqueeze(1)\n","        correct = None\n","        for j in range(target_length):\n","            decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden, encoder_hidden_outputs)\n","            squeezed_output = decoder_output.squeeze(1)\n","            for i in range(batch_size):\n","                loss += nn.functional.nll_loss(squeezed_output[i], target[i, j])\n","            decoder_input = decoder_output.argmax(dim=-1)\n","            if correct is None:\n","                correct = decoder_input == target[:, j]\n","            else:\n","                correct = (decoder_input == target[:, j]) & correct\n","        correct_words = correct.sum()\n","\n","        # for i in range(batch_size):\n","        #     if self.encoder.cell_type == 'LSTM':\n","        #         decoder_hidden = encoder_hidden_outputs[i].view(self.decoder.direction, -1), encoder_output_gate[i].view(self.decoder.direction, -1)\n","        #     else:\n","        #         decoder_hidden = encoder_hidden_outputs[i].view(self.decoder.direction, -1)\n","        #     decoder_input = target[i, 0].unsqueeze(0)\n","        #     correct = True\n","        #     for j in range(target_length):\n","        #         decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden)\n","        #         loss += nn.functional.nll_loss(decoder_output, target[i, j])\n","        #         decoder_input = torch.tensor([decoder_output.argmax().item()]).to(self.device)\n","        #         if correct and target[i, j]!= decoder_output.argmax().item():\n","        #             correct = False\n","        #     if correct:\n","        #         correct_words  += 1\n","        reported_loss = loss / (batch_size * target_length)\n","        self.log('val_loss', reported_loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n","        self.log('val_acc', correct_words/batch_size, on_epoch=True, prog_bar=True, logger=True)\n","        return loss\n","    def configure_optimizers(self):\n","        return torch.optim.Adam(self.parameters(), lr=0.001)"]},{"cell_type":"code","execution_count":99,"metadata":{},"outputs":[],"source":["encoder = Encoder(30, 64, cell_type=\"LSTM\", num_layers=1, bidirectional=True, dropout=0.1)\n","decoder = AttnDecoder(150, 64, 72, cell_type=\"LSTM\", num_layers=1, bidirectional=True)\n","model = AttnSeq2seq(encoder, decoder)"]},{"cell_type":"code","execution_count":100,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["GPU available: False, used: False\n","TPU available: False, using: 0 TPU cores\n","IPU available: False, using: 0 IPUs\n","HPU available: False, using: 0 HPUs\n","\n","  | Name    | Type        | Params\n","----------------------------------------\n","0 | encoder | Encoder     | 68.5 K\n","1 | decoder | AttnDecoder | 126 K \n","----------------------------------------\n","194 K     Trainable params\n","0         Non-trainable params\n","194 K     Total params\n","0.780     Total estimated model params size (MB)\n"]},{"name":"stdout","output_type":"stream","text":["Sanity Checking: 0it [00:00, ?it/s]"]},{"name":"stderr","output_type":"stream","text":["/home/sooraj/.local/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n","  rank_zero_warn(\n"]},{"name":"stdout","output_type":"stream","text":["                                                                           \r"]},{"name":"stderr","output_type":"stream","text":["/home/sooraj/.local/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n","  rank_zero_warn(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 0:   0%|          | 1/1599 [09:35<255:20:40, 575.24s/it, v_num=213, train_loss_step=5.100, train_acc_step=0.000]\n","Epoch 0: 100%|██████████| 1599/1599 [04:33<00:00,  5.84it/s, v_num=216, train_loss_step=1.150, train_acc_step=0.000, val_loss_step=0.970, val_loss_epoch=0.994, val_acc=0.000489, train_loss_epoch=1.220, train_acc_epoch=0.000]"]},{"name":"stderr","output_type":"stream","text":["`Trainer.fit` stopped: `max_epochs=1` reached.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 0: 100%|██████████| 1599/1599 [04:33<00:00,  5.84it/s, v_num=216, train_loss_step=1.150, train_acc_step=0.000, val_loss_step=0.970, val_loss_epoch=0.994, val_acc=0.000489, train_loss_epoch=1.220, train_acc_epoch=0.000]\n"]}],"source":["trainer = pl.Trainer(max_epochs=1)\n","trainer.fit(model, train_loader)"]},{"cell_type":"code","execution_count":106,"metadata":{},"outputs":[],"source":["sweep_attn_config = {\n","    'method': 'bayes',\n","    'metric': {\n","        'name': 'val_loss',\n","        'goal': 'minimize'\n","    },\n","    'parameters': {\n","        'hidden_size': {\n","            'values': [64, 128, 256],\n","        },\n","        'encoder_num_layers': {\n","            'values': [1, 2, 3],\n","        },\n","        'bidirectional': {\n","            'values': [True, False],\n","        },\n","        'cell_type': {\n","            'values': ['LSTM', 'GRU'],\n","        },\n","    }\n","}"]},{"cell_type":"code","execution_count":107,"metadata":{},"outputs":[],"source":["def sweep_attn_fn():\n","    wandb.init()\n","    config = wandb.config\n","    dropout_val = 0\n","    encoder=Encoder(30, config.hidden_size, config.cell_type, num_layers=config.encoder_num_layers, bidirectional=config.bidirectional)\n","    decoder = AttnDecoder(150, config.hidden_size, 64, config.cell_type, num_layers=1, bidirectional=config.bidirectional)\n","    model = AttnSeq2seq(encoder, decoder)\n","    logger = WandbLogger(project='CS6910 Assignment 3', entity='cs20b075')\n","    trainer = pl.Trainer(max_epochs=5, precision=16, logger=logger)\n","    trainer.fit(model, train_loader)"]},{"cell_type":"code","execution_count":108,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Create sweep with ID: 1t3u8y0a\n","Sweep URL: https://wandb.ai/cs20b075/CS6910%20Assignment%203/sweeps/1t3u8y0a\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ai7hogtt with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbidirectional: False\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder_num_layers: 2\n","\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 256\n","Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"]},{"data":{"text/html":["wandb version 0.15.3 is available!  To upgrade, please run:\n"," $ pip install wandb --upgrade"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Tracking run with wandb version 0.15.2"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/home/sooraj/sem/dl/assignment-3/wandb/run-20230518_221638-ai7hogtt</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/cs20b075/CS6910%20Assignment%203/runs/ai7hogtt' target=\"_blank\">lilac-sweep-1</a></strong> to <a href='https://wandb.ai/cs20b075/CS6910%20Assignment%203' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/cs20b075/CS6910%20Assignment%203/sweeps/1t3u8y0a' target=\"_blank\">https://wandb.ai/cs20b075/CS6910%20Assignment%203/sweeps/1t3u8y0a</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/cs20b075/CS6910%20Assignment%203' target=\"_blank\">https://wandb.ai/cs20b075/CS6910%20Assignment%203</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View sweep at <a href='https://wandb.ai/cs20b075/CS6910%20Assignment%203/sweeps/1t3u8y0a' target=\"_blank\">https://wandb.ai/cs20b075/CS6910%20Assignment%203/sweeps/1t3u8y0a</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/cs20b075/CS6910%20Assignment%203/runs/ai7hogtt' target=\"_blank\">https://wandb.ai/cs20b075/CS6910%20Assignment%203/runs/ai7hogtt</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/home/sooraj/.local/lib/python3.11/site-packages/pytorch_lightning/loggers/wandb.py:395: UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n","  rank_zero_warn(\n","/home/sooraj/.local/lib/python3.11/site-packages/lightning/fabric/connector.py:562: UserWarning: 16 is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!\n","  rank_zero_warn(\n","/home/sooraj/.local/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/accelerator_connector.py:517: UserWarning: You passed `Trainer(accelerator='cpu', precision='16-mixed')` but AMP with fp16 is not supported on CPU. Using `precision='bf16-mixed'` instead.\n","  rank_zero_warn(\n","Using bfloat16 Automatic Mixed Precision (AMP)\n","GPU available: False, used: False\n","TPU available: False, using: 0 TPU cores\n","IPU available: False, using: 0 IPUs\n","HPU available: False, using: 0 HPUs\n","\n","  | Name    | Type        | Params\n","----------------------------------------\n","0 | encoder | Encoder     | 1.1 M \n","1 | decoder | AttnDecoder | 767 K \n","----------------------------------------\n","1.8 M     Trainable params\n","0         Non-trainable params\n","1.8 M     Total params\n","7.312     Total estimated model params size (MB)\n"]},{"name":"stdout","output_type":"stream","text":["Sanity Checking: 0it [00:00, ?it/s]"]},{"name":"stderr","output_type":"stream","text":["/home/sooraj/.local/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n","  rank_zero_warn(\n"]},{"name":"stdout","output_type":"stream","text":["                                                                           \r"]},{"name":"stderr","output_type":"stream","text":["/home/sooraj/.local/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n","  rank_zero_warn(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 0:  10%|▉         | 155/1599 [01:14<11:37,  2.07it/s, v_num=ogtt, train_loss_step=1.090, train_acc_step=0.000]"]}],"source":["sweep_id = wandb.sweep(sweep=sweep_attn_config, project=\"CS6910 Assignment 3\")\n","wandb.agent(sweep_id=sweep_id, function=sweep_attn_fn, count=10)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.3"}},"nbformat":4,"nbformat_minor":4}
