{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.3"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Read the data","metadata":{}},{"cell_type":"code","source":"!pip install lightning wandb","metadata":{"execution":{"iopub.status.busy":"2023-05-16T06:34:37.818597Z","iopub.execute_input":"2023-05-16T06:34:37.819665Z","iopub.status.idle":"2023-05-16T06:34:51.401178Z","shell.execute_reply.started":"2023-05-16T06:34:37.819615Z","shell.execute_reply":"2023-05-16T06:34:51.399867Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"Requirement already satisfied: lightning in /opt/conda/lib/python3.7/site-packages (1.9.5)\nRequirement already satisfied: wandb in /opt/conda/lib/python3.7/site-packages (0.14.0)\nRequirement already satisfied: lightning-cloud>=0.5.27 in /opt/conda/lib/python3.7/site-packages (from lightning) (0.5.36)\nRequirement already satisfied: torch<4.0,>=1.10.0 in /opt/conda/lib/python3.7/site-packages (from lightning) (1.13.0)\nRequirement already satisfied: tqdm<6.0,>=4.57.0 in /opt/conda/lib/python3.7/site-packages (from lightning) (4.64.1)\nRequirement already satisfied: starlette<2.0 in /opt/conda/lib/python3.7/site-packages (from lightning) (0.22.0)\nRequirement already satisfied: urllib3<3.0 in /opt/conda/lib/python3.7/site-packages (from lightning) (1.26.14)\nRequirement already satisfied: typing-extensions<6.0,>=4.0.0 in /opt/conda/lib/python3.7/site-packages (from lightning) (4.4.0)\nRequirement already satisfied: numpy<3.0,>=1.17.2 in /opt/conda/lib/python3.7/site-packages (from lightning) (1.21.6)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from lightning) (23.0)\nRequirement already satisfied: dateutils<2.0 in /opt/conda/lib/python3.7/site-packages (from lightning) (0.6.12)\nRequirement already satisfied: lightning-utilities<2.0,>=0.6.0.post0 in /opt/conda/lib/python3.7/site-packages (from lightning) (0.8.0)\nRequirement already satisfied: croniter<1.4.0,>=1.3.0 in /opt/conda/lib/python3.7/site-packages (from lightning) (1.3.14)\nRequirement already satisfied: starsessions<2.0,>=1.2.1 in /opt/conda/lib/python3.7/site-packages (from lightning) (1.3.0)\nRequirement already satisfied: psutil<7.0 in /opt/conda/lib/python3.7/site-packages (from lightning) (5.9.3)\nRequirement already satisfied: beautifulsoup4<6.0,>=4.8.0 in /opt/conda/lib/python3.7/site-packages (from lightning) (4.11.1)\nRequirement already satisfied: pydantic<3.0 in /opt/conda/lib/python3.7/site-packages (from lightning) (1.10.4)\nRequirement already satisfied: deepdiff<8.0,>=5.7.0 in /opt/conda/lib/python3.7/site-packages (from lightning) (6.3.0)\nRequirement already satisfied: traitlets<7.0,>=5.3.0 in /opt/conda/lib/python3.7/site-packages (from lightning) (5.8.1)\nRequirement already satisfied: fastapi<0.89.0 in /opt/conda/lib/python3.7/site-packages (from lightning) (0.88.0)\nRequirement already satisfied: click<10.0 in /opt/conda/lib/python3.7/site-packages (from lightning) (8.1.3)\nRequirement already satisfied: PyYAML<8.0 in /opt/conda/lib/python3.7/site-packages (from lightning) (6.0)\nRequirement already satisfied: fsspec<2024.0,>=2022.5.0 in /opt/conda/lib/python3.7/site-packages (from lightning) (2023.1.0)\nRequirement already satisfied: torchmetrics<2.0,>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from lightning) (0.11.4)\nRequirement already satisfied: uvicorn<2.0 in /opt/conda/lib/python3.7/site-packages (from lightning) (0.20.0)\nRequirement already satisfied: arrow<3.0,>=1.2.0 in /opt/conda/lib/python3.7/site-packages (from lightning) (1.2.3)\nRequirement already satisfied: Jinja2<5.0 in /opt/conda/lib/python3.7/site-packages (from lightning) (3.1.2)\nRequirement already satisfied: rich<15.0 in /opt/conda/lib/python3.7/site-packages (from lightning) (13.2.0)\nRequirement already satisfied: websocket-client<3.0 in /opt/conda/lib/python3.7/site-packages (from lightning) (1.4.2)\nRequirement already satisfied: inquirer<5.0,>=2.10.0 in /opt/conda/lib/python3.7/site-packages (from lightning) (2.10.1)\nRequirement already satisfied: requests<4.0 in /opt/conda/lib/python3.7/site-packages (from lightning) (2.28.2)\nRequirement already satisfied: websockets<12.0 in /opt/conda/lib/python3.7/site-packages (from lightning) (11.0)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from wandb) (59.8.0)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (0.4.0)\nRequirement already satisfied: protobuf!=4.21.0,<5,>=3.12.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (3.20.3)\nRequirement already satisfied: pathtools in /opt/conda/lib/python3.7/site-packages (from wandb) (0.1.2)\nRequirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (3.1.30)\nRequirement already satisfied: setproctitle in /opt/conda/lib/python3.7/site-packages (from wandb) (1.3.2)\nRequirement already satisfied: appdirs>=1.4.3 in /opt/conda/lib/python3.7/site-packages (from wandb) (1.4.4)\nRequirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (1.18.0)\nRequirement already satisfied: python-dateutil>=2.7.0 in /opt/conda/lib/python3.7/site-packages (from arrow<3.0,>=1.2.0->lightning) (2.8.2)\nRequirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.7/site-packages (from beautifulsoup4<6.0,>=4.8.0->lightning) (2.3.2.post1)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from click<10.0->lightning) (4.11.4)\nRequirement already satisfied: pytz in /opt/conda/lib/python3.7/site-packages (from dateutils<2.0->lightning) (2023.3)\nRequirement already satisfied: ordered-set<4.2.0,>=4.0.2 in /opt/conda/lib/python3.7/site-packages (from deepdiff<8.0,>=5.7.0->lightning) (4.1.0)\nRequirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.7/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\nRequirement already satisfied: anyio<5,>=3.4.0 in /opt/conda/lib/python3.7/site-packages (from starlette<2.0->lightning) (3.6.2)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/conda/lib/python3.7/site-packages (from fsspec<2024.0,>=2022.5.0->lightning) (3.8.3)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.7/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.10)\nRequirement already satisfied: readchar>=3.0.6 in /opt/conda/lib/python3.7/site-packages (from inquirer<5.0,>=2.10.0->lightning) (4.0.5)\nRequirement already satisfied: blessed>=1.19.0 in /opt/conda/lib/python3.7/site-packages (from inquirer<5.0,>=2.10.0->lightning) (1.19.1)\nRequirement already satisfied: python-editor>=1.0.4 in /opt/conda/lib/python3.7/site-packages (from inquirer<5.0,>=2.10.0->lightning) (1.0.4)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.7/site-packages (from Jinja2<5.0->lightning) (2.1.1)\nRequirement already satisfied: pyjwt in /opt/conda/lib/python3.7/site-packages (from lightning-cloud>=0.5.27->lightning) (2.6.0)\nRequirement already satisfied: python-multipart in /opt/conda/lib/python3.7/site-packages (from lightning-cloud>=0.5.27->lightning) (0.0.6)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<4.0->lightning) (3.4)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.7/site-packages (from requests<4.0->lightning) (2.1.1)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<4.0->lightning) (2022.12.7)\nRequirement already satisfied: markdown-it-py<3.0.0,>=2.1.0 in /opt/conda/lib/python3.7/site-packages (from rich<15.0->lightning) (2.1.0)\nRequirement already satisfied: pygments<3.0.0,>=2.6.0 in /opt/conda/lib/python3.7/site-packages (from rich<15.0->lightning) (2.14.0)\nRequirement already satisfied: itsdangerous<3.0.0,>=2.0.1 in /opt/conda/lib/python3.7/site-packages (from starsessions<2.0,>=1.2.1->lightning) (2.1.2)\nRequirement already satisfied: h11>=0.8 in /opt/conda/lib/python3.7/site-packages (from uvicorn<2.0->lightning) (0.14.0)\nRequirement already satisfied: asynctest==0.13.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec<2024.0,>=2022.5.0->lightning) (0.13.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec<2024.0,>=2022.5.0->lightning) (1.3.3)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.7/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec<2024.0,>=2022.5.0->lightning) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec<2024.0,>=2022.5.0->lightning) (1.8.2)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.7/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec<2024.0,>=2022.5.0->lightning) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.7/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec<2024.0,>=2022.5.0->lightning) (4.0.2)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec<2024.0,>=2022.5.0->lightning) (22.2.0)\nRequirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.7/site-packages (from anyio<5,>=3.4.0->starlette<2.0->lightning) (1.3.0)\nRequirement already satisfied: wcwidth>=0.1.4 in /opt/conda/lib/python3.7/site-packages (from blessed>=1.19.0->inquirer<5.0,>=2.10.0->lightning) (0.2.6)\nRequirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.7/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.0)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->click<10.0->lightning) (3.11.0)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.7/site-packages (from markdown-it-py<3.0.0,>=2.1.0->rich<15.0->lightning) (0.1.2)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"!WANDB_API_KEY=8c780297be240a84f5c8b7d669cb158839b2637a","metadata":{"execution":{"iopub.status.busy":"2023-05-16T06:34:51.404518Z","iopub.execute_input":"2023-05-16T06:34:51.405632Z","iopub.status.idle":"2023-05-16T06:34:52.413179Z","shell.execute_reply.started":"2023-05-16T06:34:51.405581Z","shell.execute_reply":"2023-05-16T06:34:52.411683Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport torch \nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nimport numpy as np\nimport lightning as pl\nfrom pytorch_lightning.loggers import WandbLogger\nimport random\nimport wandb","metadata":{"execution":{"iopub.status.busy":"2023-05-16T06:34:52.416363Z","iopub.execute_input":"2023-05-16T06:34:52.417245Z","iopub.status.idle":"2023-05-16T06:34:52.424292Z","shell.execute_reply.started":"2023-05-16T06:34:52.417197Z","shell.execute_reply":"2023-05-16T06:34:52.423163Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"!WANDB_API_KEY=8c780297be240a84f5c8b7d669cb158839b2637a wandb login","metadata":{"execution":{"iopub.status.busy":"2023-05-16T06:34:52.429462Z","iopub.execute_input":"2023-05-16T06:34:52.430470Z","iopub.status.idle":"2023-05-16T06:34:55.047539Z","shell.execute_reply.started":"2023-05-16T06:34:52.430426Z","shell.execute_reply":"2023-05-16T06:34:55.046287Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcs20b075\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"}]},{"cell_type":"code","source":"path = \"/kaggle/input/aksharantar/aksharantar_sampled/hin\"\ntrain_path = path + \"/hin_train.csv\"\nvalid_path = path + \"/hin_valid.csv\"\ntest_path = path + \"/hin_test.csv\"","metadata":{"execution":{"iopub.status.busy":"2023-05-16T06:36:04.775718Z","iopub.execute_input":"2023-05-16T06:36:04.776933Z","iopub.status.idle":"2023-05-16T06:36:04.784344Z","shell.execute_reply.started":"2023-05-16T06:36:04.776878Z","shell.execute_reply":"2023-05-16T06:36:04.783193Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"def get_data(path):\n    dataset = pd.read_csv(path, header=None)\n    dataset = dataset.values\n    input = dataset[:, 0]\n    output = dataset[:, 1]\n    return input, output","metadata":{"execution":{"iopub.status.busy":"2023-05-16T06:36:05.581978Z","iopub.execute_input":"2023-05-16T06:36:05.583197Z","iopub.status.idle":"2023-05-16T06:36:05.589915Z","shell.execute_reply.started":"2023-05-16T06:36:05.583147Z","shell.execute_reply":"2023-05-16T06:36:05.588474Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"train_dataset = get_data(train_path)\nval_dataset = get_data(valid_path)","metadata":{"execution":{"iopub.status.busy":"2023-05-16T06:36:06.239535Z","iopub.execute_input":"2023-05-16T06:36:06.239945Z","iopub.status.idle":"2023-05-16T06:36:06.337010Z","shell.execute_reply.started":"2023-05-16T06:36:06.239908Z","shell.execute_reply":"2023-05-16T06:36:06.335895Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"def convert_word_to_tensor(word, lang):\n    lang_to_int = {'SOS': 0, 'EOS': 1, 'PAD': 2}\n    if lang == 'eng':\n        lang_to_int.update({chr(i): i-94 for i in range(97, 123)})\n    elif lang == 'hin':\n        lang_to_int.update({chr(i): i-2300 for i in range(2304, 2432)})\n    \n    a = [lang_to_int['SOS']]\n\n    for i in word:\n        a.append(lang_to_int[i])\n\n    a.append(lang_to_int['EOS'])\n    if len(a) < 24:\n        a.extend([lang_to_int['PAD']]*(24-len(a)))\n    \n    return torch.tensor(a)","metadata":{"execution":{"iopub.status.busy":"2023-05-16T06:36:07.895677Z","iopub.execute_input":"2023-05-16T06:36:07.896068Z","iopub.status.idle":"2023-05-16T06:36:07.905845Z","shell.execute_reply.started":"2023-05-16T06:36:07.896033Z","shell.execute_reply":"2023-05-16T06:36:07.904490Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"class AksharantarDataset(Dataset):\n    def __init__(self, dataset):\n        super().__init__()\n        self.dataset = dataset\n        self.input = dataset[0]\n        self.output = dataset[1]\n        mask = np.array([len(elem) < 21 for elem in self.input]) & np.array([len(elem) < 21 for elem in self.output])\n        self.input = self.input[mask]\n        self.output = self.output[mask]\n        self.len = len(self.input)\n    \n    def __getitem__(self, index):\n        return convert_word_to_tensor(self.input[index], 'eng'), convert_word_to_tensor(self.output[index], 'hin')\n    \n    def __len__(self):\n        return self.len","metadata":{"execution":{"iopub.status.busy":"2023-05-16T06:36:08.647495Z","iopub.execute_input":"2023-05-16T06:36:08.647884Z","iopub.status.idle":"2023-05-16T06:36:08.659827Z","shell.execute_reply.started":"2023-05-16T06:36:08.647849Z","shell.execute_reply":"2023-05-16T06:36:08.658704Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"class CustomDataModule(pl.LightningDataModule):\n    def __init__(self, dataset, val_dataset, batch_size=32):\n        super().__init__()\n        self.dataset = train_dataset\n        self.val_dataset = val_dataset\n        self.batch_size = batch_size\n\n    def train_dataloader(self):\n        dataset = AksharantarDataset(self.dataset)\n        return DataLoader(dataset, batch_size=self.batch_size, num_workers=2)\n    def val_dataloader(self):\n        dataset = AksharantarDataset(self.val_dataset)\n        return DataLoader(dataset, batch_size=self.batch_size, num_workers=2)","metadata":{"execution":{"iopub.status.busy":"2023-05-16T06:36:09.071756Z","iopub.execute_input":"2023-05-16T06:36:09.072136Z","iopub.status.idle":"2023-05-16T06:36:09.080077Z","shell.execute_reply.started":"2023-05-16T06:36:09.072103Z","shell.execute_reply":"2023-05-16T06:36:09.078868Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"train_loader = CustomDataModule(train_dataset, val_dataset, 32)\n# val_loader = CustomDataModule(val_dataset, 32)","metadata":{"execution":{"iopub.status.busy":"2023-05-16T06:36:09.738298Z","iopub.execute_input":"2023-05-16T06:36:09.739374Z","iopub.status.idle":"2023-05-16T06:36:09.753016Z","shell.execute_reply.started":"2023-05-16T06:36:09.739322Z","shell.execute_reply":"2023-05-16T06:36:09.751525Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"markdown","source":"# Encoder model","metadata":{}},{"cell_type":"code","source":"class Encoder(pl.LightningModule):\n    def __init__(self, input_size, hidden_size, cell_type, num_layers=1, dropout=0, bidirectional=False):\n        super().__init__()\n        self.hidden_size = hidden_size\n        self.embedding = nn.Embedding(input_size, hidden_size)\n        self.cell_type = cell_type\n        if cell_type == 'LSTM':\n            self.rnn = nn.LSTM\n        elif cell_type == 'GRU':\n            self.rnn = nn.GRU\n        else:\n            self.rnn = nn.RNN\n        self.direction = 2 if bidirectional else 1\n        self.first_cell = self.rnn(hidden_size, hidden_size, bidirectional=bidirectional)\n        self.rnns = nn.ModuleList([self.rnn(hidden_size*self.direction, hidden_size, bidirectional=bidirectional)]*(num_layers-1))\n        self.num_layers = num_layers\n\n    def forward(self, input, hidden):\n        embedded = self.embedding(input)\n        # embedded = embedded.view(1, 1, -1)\n        output = embedded\n        output, hidden = self.first_cell(output, hidden)\n        for i in range(self.num_layers-1):\n            output, hidden = self.rnns[i](output, hidden)\n        return output, hidden\n\n    def init_hidden(self):\n        if self.cell_type == 'LSTM':\n            return torch.zeros(self.direction, self.hidden_size), torch.zeros(self.direction, self.hidden_size)\n        return torch.zeros(self.direction, self.hidden_size, device=self.device)","metadata":{"execution":{"iopub.status.busy":"2023-05-16T06:36:11.017766Z","iopub.execute_input":"2023-05-16T06:36:11.018191Z","iopub.status.idle":"2023-05-16T06:36:11.032010Z","shell.execute_reply.started":"2023-05-16T06:36:11.018152Z","shell.execute_reply":"2023-05-16T06:36:11.030663Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"markdown","source":"# Decoder","metadata":{}},{"cell_type":"code","source":"class Decoder(pl.LightningModule):\n    def __init__(self, output_size, hidden_size, cell_type, num_layers=1, bidirectional=False, dropout=0):\n        super().__init__()\n        self.hidden_size = hidden_size\n        self.embedding = nn.Embedding(output_size, hidden_size)\n        if cell_type == 'LSTM':\n            self.cell_type = nn.LSTM\n        elif cell_type == 'GRU':\n            self.cell_type = nn.GRU\n        else:\n            self.cell_type = nn.RNN\n        self.first_cell = self.cell_type(hidden_size, hidden_size, bidirectional=bidirectional, batch_first=True)\n        self.direction = 2 if bidirectional else 1\n        self.rnns= nn.ModuleList([self.cell_type(hidden_size*self.direction, hidden_size, bidirectional=bidirectional, batch_first=True)]*(num_layers-1))\n        self.out = nn.Linear(hidden_size*self.direction, output_size)\n        self.softmax = nn.LogSoftmax(dim=-1)\n        self.num_layers = num_layers\n\n    def forward(self, input, hidden):\n        output = self.embedding(input)\n        output = nn.functional.relu(output)\n        output, hidden = self.first_cell(output, hidden)\n        for i in range(self.num_layers-1):\n            output, hidden = self.rnns[i](output, hidden)\n        linear_output = self.out(output)\n        output = self.softmax(self.out(output))\n        if output.shape[0] == 1:\n            output = output.squeeze(0)\n        return output, hidden","metadata":{"execution":{"iopub.status.busy":"2023-05-16T06:36:11.637209Z","iopub.execute_input":"2023-05-16T06:36:11.637653Z","iopub.status.idle":"2023-05-16T06:36:11.652484Z","shell.execute_reply.started":"2023-05-16T06:36:11.637615Z","shell.execute_reply":"2023-05-16T06:36:11.651078Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"markdown","source":"# Seq2seq model","metadata":{}},{"cell_type":"code","source":"class Seq2seq(pl.LightningModule):\n    def __init__(self, encoder, decoder):\n        super().__init__()\n        self.encoder = encoder.to(self.device)\n        self.decoder = decoder.to(self.device)\n\n    def forward(self, input):\n        batched = True if len(input.shape) > 1 else False\n        if not batched:\n            input = input.unsqueeze(0)\n        batch_size = input.shape[0]\n        input_length = input.shape[1]\n        \n        self.encoder = self.encoder.to(self.device)\n        self.decoder = self.decoder.to(self.device)\n        \n        encoder_hidden=None\n        \n        encoder_hidden_outputs = torch.zeros(batch_size, self.encoder.hidden_size*self.encoder.direction, device=self.device)\n        encoder_output_gate = torch.zeros(batch_size, self.encoder.hidden_size*self.encoder.direction, device=self.device)\n        for i in range(batch_size):\n            if self.encoder.cell_type == 'LSTM':\n                a, b = self.encoder.init_hidden()\n                encoder_hidden = a.to(self.device), b.to(self.device)\n            else:\n                encoder_hidden = self.encoder.init_hidden().to(self.device)\n\n            _, encoder_hidden = self.encoder(input[i], encoder_hidden)\n            if self.encoder.cell_type == 'LSTM':\n                encoder_hidden_outputs[i] = encoder_hidden[0].flatten()\n                encoder_output_gate[i] = encoder_hidden[1].flatten()\n            else:\n                encoder_hidden_outputs[i] = encoder_hidden.flatten()\n        output_sequence = [[]]*batch_size\n        for i in range(batch_size):\n            if self.encoder.cell_type == 'LSTM':\n                decoder_hidden = encoder_hidden_outputs[i].view(self.decoder.direction, -1), encoder_output_gate[i].view(self.decoder.direction, -1)\n            else:\n                decoder_hidden = encoder_hidden_outputs[i].view(self.decoder.direction, -1)\n            decoder_input = torch.tensor([0], device=self.device)\n            output_sequence[i].append(decoder_input)\n            for j in range(input_length):\n                decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden)\n                decoder_input = torch.tensor([decoder_output.argmax().item()]).to(self.device)\n                output_sequence[i].append(decoder_input)\n        output_sequence = torch.tensor(output_sequence, device=self.device)\n        if not batched:\n            output_sequence = output_sequence.squeeze(0)\n        return output_sequence\n        \n    def training_step(self, batch, batch_idx):\n        input, target = batch\n        \n        self.encoder = self.encoder.to(self.device)\n        self.decoder = self.decoder.to(self.device)\n        \n        batched = True if len(input.shape) > 1 else False\n        if not batched:\n            input = input.unsqueeze(0)\n            target = target.unsqueeze(0)\n        input = input.to(self.device)\n        target = target.to(self.device)\n        batch_size = input.shape[0]\n        input_length = input.shape[1]\n        target_length = target.shape[1]\n\n        encoder_hidden = None\n        encoder_hidden_outputs = torch.zeros(batch_size, self.encoder.hidden_size*self.encoder.direction, device=self.device)\n        encoder_output_gate = torch.zeros(batch_size, self.encoder.hidden_size*self.encoder.direction, device=self.device)\n        for i in range(batch_size):\n            if self.encoder.cell_type == 'LSTM':\n                a, b = self.encoder.init_hidden()\n                encoder_hidden = a.to(self.device), b.to(self.device)\n            else:\n                encoder_hidden = self.encoder.init_hidden().to(self.device)\n\n            _, encoder_hidden = self.encoder(input[i], encoder_hidden)\n            if self.encoder.cell_type == 'LSTM':\n                encoder_hidden_outputs[i] = encoder_hidden[0].flatten()\n                encoder_output_gate[i] = encoder_hidden[1].flatten()\n            else:\n                encoder_hidden_outputs[i] = encoder_hidden.flatten()\n        loss = 0\n        correct_words = 0\n        if random.random() < 0.5: \n            if self.encoder.cell_type == 'LSTM':\n                decoder_hidden = encoder_hidden_outputs.view(batch_size, self.decoder.direction, -1).transpose(0, 1).contiguous(), encoder_output_gate.view(batch_size, self.decoder.direction, -1).transpose(0, 1).contiguous()\n            else:\n                decoder_hidden = encoder_hidden_outputs.view(batch_size, self.decoder.direction, -1).transpose(0, 1).contiguous()\n            decoder_input = target[:, 0].unsqueeze(1)\n            correct = None\n            for j in range(target_length):\n                decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden)\n                squeezed_output = decoder_output.squeeze(1)\n                for i in range(batch_size):\n                    loss += nn.functional.nll_loss(squeezed_output[i], target[i, j])\n                decoder_input = target[:, j].unsqueeze(1)\n                if correct is None:\n                    correct = decoder_output.argmax(dim=-1) == target[:, j]\n                else:\n                    correct = (decoder_output.argmax(dim=-1) == target[:, j]) & correct\n            correct_words = correct.sum()\n\n            # for i in range(batch_size):\n            #     if self.encoder.cell_type == 'LSTM':\n            #         decoder_hidden = encoder_hidden_outputs[i].view(self.decoder.direction, -1), encoder_output_gate[i].view(self.decoder.direction, -1)\n            #     else:\n            #         decoder_hidden = encoder_hidden_outputs[i].view(self.decoder.direction, -1)\n            #     correct = True\n            #     for j in range(target_length):\n            #         decoder_output, decoder_hidden = self.decoder(target[i, j].unsqueeze(0), decoder_hidden)\n            #         loss += nn.functional.nll_loss(decoder_output, target[i, j])\n            #         if correct and target[i, j]!=decoder_output.argmax().item():\n            #             correct=False\n            #     if correct:\n            #         correct_words += 1\n        else:\n            if self.encoder.cell_type == 'LSTM':\n                decoder_hidden = encoder_hidden_outputs.view(batch_size, self.decoder.direction, -1).transpose(0, 1).contiguous(), encoder_output_gate.view(batch_size, self.decoder.direction, -1).transpose(0, 1).contiguous()\n            else:\n                decoder_hidden = encoder_hidden_outputs.view(batch_size, self.decoder.direction, -1).transpose(0, 1).contiguous()\n            decoder_input = target[:, 0].unsqueeze(1)\n            correct = None\n            for j in range(target_length):\n                decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden)\n                squeezed_output = decoder_output.squeeze(1)\n                for i in range(batch_size):\n                    loss += nn.functional.nll_loss(squeezed_output[i], target[i, j])\n                decoder_input = decoder_output.argmax(dim=-1)\n                if correct is None:\n                    correct = decoder_input == target[:, j]\n                else:\n                    correct = (decoder_input == target[:, j]) & correct\n            correct_words = correct.sum()\n            # for i in range(batch_size):\n            #     if self.encoder.cell_type == 'LSTM':\n            #         decoder_hidden = encoder_hidden_outputs[i].view(self.decoder.direction, -1), encoder_output_gate[i].view(self.decoder.direction, -1)\n            #     else:\n            #         decoder_hidden = encoder_hidden_outputs[i].view(self.decoder.direction, -1)\n            #     decoder_input = target[i, 0].unsqueeze(0)\n            #     correct = True\n            #     for j in range(target_length):\n            #         decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden)\n            #         loss += nn.functional.nll_loss(decoder_output, target[i, j])\n            #         decoder_input = torch.tensor([decoder_output.argmax().item()]).to(self.device)\n            #         if correct and target[i, j]!= decoder_output.argmax().item():\n            #             correct = False\n            #     if correct:\n            #         correct_words  += 1\n\n\n        # print(correct_words, batch_size, correct_words/batch_size)\n        reported_loss = loss / (batch_size * target_length)\n        self.log('train_loss', reported_loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n        self.log('train_acc', correct_words/batch_size, on_step=True, on_epoch=True, logger=True, prog_bar=True)\n        return loss\n    def validation_step(self, batch, batch_idx):\n        input, target = batch\n        self.encoder = self.encoder.to(self.device)\n        self.decoder = self.decoder.to(self.device)\n        batched = True if len(input.shape) > 1 else False\n        if not batched:\n            input = input.unsqueeze(0)\n            target = target.unsqueeze(0)\n        batch_size = input.shape[0]\n        input_length = input.shape[1]\n        target_length = target.shape[1]\n        encoder_hidden = None\n        \n        \n        encoder_hidden_outputs = torch.zeros(batch_size, self.encoder.hidden_size*self.encoder.direction, device=self.device)\n        encoder_output_gate = torch.zeros(batch_size, self.encoder.hidden_size*self.encoder.direction, device=self.device)\n        for i in range(batch_size):\n            if self.encoder.cell_type == 'LSTM':\n                a, b = self.encoder.init_hidden()\n                encoder_hidden = a.to(self.device), b.to(self.device)\n            else:\n                encoder_hidden = self.encoder.init_hidden().to(self.device)\n\n            _, encoder_hidden = self.encoder(input[i], encoder_hidden)\n            if self.encoder.cell_type == 'LSTM':\n                encoder_hidden_outputs[i] = encoder_hidden[0].flatten()\n                encoder_output_gate[i] = encoder_hidden[1].flatten()\n            else:\n                encoder_hidden_outputs[i] = encoder_hidden.flatten()\n        loss = 0\n        correct_words = 0\n\n        if self.encoder.cell_type == 'LSTM':\n            decoder_hidden = encoder_hidden_outputs.view(batch_size, self.decoder.direction, -1).transpose(0, 1).contiguous(), encoder_output_gate.view(batch_size, self.decoder.direction, -1).transpose(0, 1).contiguous()\n        else:\n            decoder_hidden = encoder_hidden_outputs.view(batch_size, self.decoder.direction, -1).transpose(0, 1).contiguous()\n        decoder_input = target[:, 0].unsqueeze(1)\n        correct = None\n        for j in range(target_length):\n            decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden)\n            squeezed_output = decoder_output.squeeze(1)\n            for i in range(batch_size):\n                loss += nn.functional.nll_loss(squeezed_output[i], target[i, j])\n            decoder_input = decoder_output.argmax(dim=-1)\n            if correct is None:\n                correct = decoder_input == target[:, j]\n            else:\n                correct = (decoder_input == target[:, j]) & correct\n        correct_words = correct.sum()\n\n        # for i in range(batch_size):\n        #     if self.encoder.cell_type == 'LSTM':\n        #         decoder_hidden = encoder_hidden_outputs[i].view(self.decoder.direction, -1), encoder_output_gate[i].view(self.decoder.direction, -1)\n        #     else:\n        #         decoder_hidden = encoder_hidden_outputs[i].view(self.decoder.direction, -1)\n        #     decoder_input = target[i, 0].unsqueeze(0)\n        #     correct = True\n        #     for j in range(target_length):\n        #         decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden)\n        #         loss += nn.functional.nll_loss(decoder_output, target[i, j])\n        #         decoder_input = torch.tensor([decoder_output.argmax().item()]).to(self.device)\n        #         if correct and target[i, j]!= decoder_output.argmax().item():\n        #             correct = False\n        #     if correct:\n        #         correct_words  += 1\n        reported_loss = loss / (batch_size * target_length)\n        self.log('val_loss', reported_loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n        self.log('val_acc', correct_words/batch_size, on_step=True, on_epoch=True, logger=True)\n        return loss\n    def configure_optimizers(self):\n        return torch.optim.Adam(self.parameters(), lr=0.001)","metadata":{"execution":{"iopub.status.busy":"2023-05-16T06:46:55.482120Z","iopub.execute_input":"2023-05-16T06:46:55.482586Z","iopub.status.idle":"2023-05-16T06:46:55.549975Z","shell.execute_reply.started":"2023-05-16T06:46:55.482547Z","shell.execute_reply":"2023-05-16T06:46:55.548793Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"encoder = Encoder(30, 100, cell_type=\"LSTM\", num_layers=2, bidirectional=True, dropout=0.1)\ndecoder = Decoder(150, 100, cell_type=\"LSTM\", num_layers=2, bidirectional=True)\nmodel = Seq2seq(encoder, decoder)","metadata":{"execution":{"iopub.status.busy":"2023-05-16T06:46:55.860979Z","iopub.execute_input":"2023-05-16T06:46:55.861327Z","iopub.status.idle":"2023-05-16T06:46:55.882562Z","shell.execute_reply.started":"2023-05-16T06:46:55.861294Z","shell.execute_reply":"2023-05-16T06:46:55.881535Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"trainer = pl.Trainer(accelerator='gpu', devices=2, max_epochs=10)\ntrainer.fit(model, train_loader)","metadata":{"execution":{"iopub.status.busy":"2023-05-16T06:46:56.690429Z","iopub.execute_input":"2023-05-16T06:46:56.691531Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"INFO: Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/2\nINFO: Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/2\nINFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\nINFO: LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1]\nINFO: \n  | Name    | Type    | Params\n------------------------------------\n0 | encoder | Encoder | 406 K \n1 | decoder | Decoder | 448 K \n------------------------------------\n854 K     Trainable params\n0         Non-trainable params\n854 K     Total params\n3.418     Total estimated model params size (MB)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Sanity Checking: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:209: UserWarning: num_workers>0, persistent_workers=False, and strategy=ddp_spawn may result in data loading bottlenecks. Consider setting persistent_workers=True (this is a limitation of Python .spawn() and PyTorch)\n  \"num_workers>0, persistent_workers=False, and strategy=ddp_spawn\"\n/opt/conda/lib/python3.7/site-packages/lightning/pytorch/trainer/connectors/logger_connector/result.py:543: PossibleUserWarning: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n  category=PossibleUserWarning,\n/opt/conda/lib/python3.7/site-packages/lightning/pytorch/trainer/connectors/logger_connector/result.py:543: PossibleUserWarning: It is recommended to use `self.log('val_acc', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n  category=PossibleUserWarning,\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d29d2b933b6e42b4b3a3fa9ecb3c1165"}},"metadata":{}},{"name":"stderr","text":"[W reducer.cpp:1298] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n[W reducer.cpp:1298] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n","output_type":"stream"}]},{"cell_type":"code","source":"def convert_tensor_to_word(tensor, lang):\n    int_to_lang = {0: 'SOS', 1: 'EOS', 2: 'PAD'}\n    if lang == 'eng':\n        int_to_lang.update({i-94: chr(i) for i in range(97, 123)})\n    elif lang == 'hin':\n        int_to_lang.update({i-2300: chr(i) for i in range(2304, 2432)})\n    \n    word = ''\n    for i in tensor:\n        word += int_to_lang[i.item()]\n    return word","metadata":{"execution":{"iopub.execute_input":"2023-05-11T20:24:54.863147Z","iopub.status.busy":"2023-05-11T20:24:54.862722Z","iopub.status.idle":"2023-05-11T20:24:54.871728Z","shell.execute_reply":"2023-05-11T20:24:54.870454Z","shell.execute_reply.started":"2023-05-11T20:24:54.863108Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sweep_config = {\n    'method': 'bayes',\n    'metric': {\n        'name': 'val_loss',\n        'goal': 'minimize'\n    },\n    'parameters': {\n        'hidden_size': {\n            'values': [16, 32, 64],\n        },\n        'encoder_num_layers': {\n            'values': [1, 2, 3],\n        },\n        'decoder_num_layers': {\n            'values': [1, 2, 3],\n        },\n        'bidirectional': {\n            'values': [True, False],\n        },\n        'cell_type': {\n            'values': ['LSTM', 'GRU'],\n        },\n    }\n}","metadata":{"execution":{"iopub.execute_input":"2023-05-11T20:24:55.521250Z","iopub.status.busy":"2023-05-11T20:24:55.519868Z","iopub.status.idle":"2023-05-11T20:24:55.529506Z","shell.execute_reply":"2023-05-11T20:24:55.528393Z","shell.execute_reply.started":"2023-05-11T20:24:55.521200Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def sweep_fn():\n    wandb.init()\n    config = wandb.config\n    dropout_val = 0\n    encoder=Encoder(30, config.hidden_size, config.cell_type, num_layers=config.encoder_num_layers, bidirectional=config.bidirectional)\n    decoder = Decoder(150, config.hidden_size, config.cell_type, num_layers=config.decoder_num_layers, bidirectional=config.bidirectional)\n    model = Seq2seq(encoder, decoder)\n    logger = WandbLogger(project='CS6910 Assignment 3', entity='cs20b075')\n    trainer = pl.Trainer(accelerator='gpu', devices=2, max_epochs=5, precision=16, logger=logger)\n    trainer.fit(model, train_loader)","metadata":{"execution":{"iopub.execute_input":"2023-05-11T20:24:56.814281Z","iopub.status.busy":"2023-05-11T20:24:56.812905Z","iopub.status.idle":"2023-05-11T20:24:56.823454Z","shell.execute_reply":"2023-05-11T20:24:56.822264Z","shell.execute_reply.started":"2023-05-11T20:24:56.814223Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wandb.login(key=\"8c780297be240a84f5c8b7d669cb158839b2637a\")","metadata":{"execution":{"iopub.execute_input":"2023-05-11T20:24:59.204864Z","iopub.status.busy":"2023-05-11T20:24:59.204190Z","iopub.status.idle":"2023-05-11T20:24:59.305703Z","shell.execute_reply":"2023-05-11T20:24:59.304455Z","shell.execute_reply.started":"2023-05-11T20:24:59.204820Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sweep_id = wandb.sweep(sweep=sweep_config, project=\"CS6910 Assignment 3\")\nwandb.agent(sweep_id=sweep_id, function=sweep_fn, count=10)","metadata":{"execution":{"iopub.execute_input":"2023-05-11T20:25:02.475513Z","iopub.status.busy":"2023-05-11T20:25:02.474451Z","iopub.status.idle":"2023-05-11T20:29:19.350116Z","shell.execute_reply":"2023-05-11T20:29:19.346270Z","shell.execute_reply.started":"2023-05-11T20:25:02.475451Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wandb.finish()","metadata":{"execution":{"iopub.execute_input":"2023-05-11T20:19:23.845801Z","iopub.status.busy":"2023-05-11T20:19:23.841384Z","iopub.status.idle":"2023-05-11T20:19:23.852667Z","shell.execute_reply":"2023-05-11T20:19:23.850824Z","shell.execute_reply.started":"2023-05-11T20:19:23.845753Z"},"trusted":true},"execution_count":null,"outputs":[]}]}