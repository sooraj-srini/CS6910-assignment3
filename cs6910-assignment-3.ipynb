{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2023-04-14T13:01:27.799207Z","iopub.status.busy":"2023-04-14T13:01:27.798703Z","iopub.status.idle":"2023-04-14T13:01:28.930259Z","shell.execute_reply":"2023-04-14T13:01:28.928962Z","shell.execute_reply.started":"2023-04-14T13:01:27.799166Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["ls: cannot access '/kaggle/input/aksharantar/aksharantar_sampled/hin': No such file or directory\n"]}],"source":["!ls /kaggle/input/aksharantar/aksharantar_sampled/hin"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-04-14T12:58:53.068929Z","iopub.status.busy":"2023-04-14T12:58:53.068283Z","iopub.status.idle":"2023-04-14T12:59:10.858813Z","shell.execute_reply":"2023-04-14T12:59:10.857402Z","shell.execute_reply.started":"2023-04-14T12:58:53.068876Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Defaulting to user installation because normal site-packages is not writeable\n","Requirement already satisfied: lightning in /home/sooraj/.local/lib/python3.10/site-packages (2.0.1)\n","Requirement already satisfied: wandb in /home/sooraj/.local/lib/python3.10/site-packages (0.13.10)\n","Requirement already satisfied: click<10.0 in /home/sooraj/.local/lib/python3.10/site-packages (from lightning) (8.1.3)\n","Requirement already satisfied: lightning-utilities<2.0,>=0.7.0 in /home/sooraj/.local/lib/python3.10/site-packages (from lightning) (0.8.0)\n","Requirement already satisfied: PyYAML<8.0,>=5.4 in /home/sooraj/.local/lib/python3.10/site-packages (from lightning) (6.0)\n","Requirement already satisfied: starsessions<2.0,>=1.2.1 in /home/sooraj/.local/lib/python3.10/site-packages (from lightning) (1.3.0)\n","Requirement already satisfied: pytorch-lightning in /home/sooraj/.local/lib/python3.10/site-packages (from lightning) (2.0.1)\n","Requirement already satisfied: websockets<12.0 in /home/sooraj/.local/lib/python3.10/site-packages (from lightning) (10.4)\n","Requirement already satisfied: websocket-client<3.0 in /home/sooraj/.local/lib/python3.10/site-packages (from lightning) (1.4.0)\n","Requirement already satisfied: fsspec[http]<2025.0,>2021.06.0 in /home/sooraj/.local/lib/python3.10/site-packages (from lightning) (2022.11.0)\n","Requirement already satisfied: torchmetrics<2.0,>=0.7.0 in /home/sooraj/.local/lib/python3.10/site-packages (from lightning) (0.11.4)\n","Requirement already satisfied: Jinja2<5.0 in /home/sooraj/.local/lib/python3.10/site-packages (from lightning) (3.1.2)\n","Requirement already satisfied: fastapi<0.89.0 in /home/sooraj/.local/lib/python3.10/site-packages (from lightning) (0.78.0)\n","Requirement already satisfied: rich<15.0,>=12.3.0 in /usr/lib/python3.10/site-packages (from lightning) (13.3.3)\n","Requirement already satisfied: starlette<2.0 in /home/sooraj/.local/lib/python3.10/site-packages (from lightning) (0.19.1)\n","Requirement already satisfied: psutil<7.0 in /home/sooraj/.local/lib/python3.10/site-packages (from lightning) (5.9.0)\n","Requirement already satisfied: dateutils<2.0 in /home/sooraj/.local/lib/python3.10/site-packages (from lightning) (0.6.12)\n","Requirement already satisfied: typing-extensions<6.0,>=4.0.0 in /home/sooraj/.local/lib/python3.10/site-packages (from lightning) (4.2.0)\n","Requirement already satisfied: numpy<3.0,>=1.17.2 in /home/sooraj/.local/lib/python3.10/site-packages (from lightning) (1.23.3)\n","Requirement already satisfied: traitlets<7.0,>=5.3.0 in /home/sooraj/.local/lib/python3.10/site-packages (from lightning) (5.9.0)\n","Requirement already satisfied: tqdm<6.0,>=4.57.0 in /home/sooraj/.local/lib/python3.10/site-packages (from lightning) (4.64.1)\n","Requirement already satisfied: pydantic<3.0 in /home/sooraj/.local/lib/python3.10/site-packages (from lightning) (1.9.1)\n","Requirement already satisfied: croniter<1.4.0,>=1.3.0 in /home/sooraj/.local/lib/python3.10/site-packages (from lightning) (1.3.10)\n","Requirement already satisfied: packaging<25.0,>=17.1 in /usr/lib/python3.10/site-packages (from lightning) (23.0)\n","Requirement already satisfied: urllib3<3.0 in /home/sooraj/.local/lib/python3.10/site-packages (from lightning) (1.25.11)\n","Requirement already satisfied: requests<4.0 in /home/sooraj/.local/lib/python3.10/site-packages (from lightning) (2.28.2)\n","Requirement already satisfied: beautifulsoup4<6.0,>=4.8.0 in /usr/lib/python3.10/site-packages (from lightning) (4.11.2)\n","Requirement already satisfied: arrow<3.0,>=1.2.0 in /home/sooraj/.local/lib/python3.10/site-packages (from lightning) (1.2.3)\n","Requirement already satisfied: lightning-cloud>=0.5.31 in /home/sooraj/.local/lib/python3.10/site-packages (from lightning) (0.5.32)\n","Requirement already satisfied: torch<4.0,>=1.11.0 in /home/sooraj/.local/lib/python3.10/site-packages (from lightning) (1.11.0)\n","Requirement already satisfied: deepdiff<8.0,>=5.7.0 in /home/sooraj/.local/lib/python3.10/site-packages (from lightning) (6.3.0)\n","Requirement already satisfied: uvicorn<2.0 in /home/sooraj/.local/lib/python3.10/site-packages (from lightning) (0.17.6)\n","Requirement already satisfied: inquirer<5.0,>=2.10.0 in /home/sooraj/.local/lib/python3.10/site-packages (from lightning) (3.1.3)\n","Requirement already satisfied: setuptools in /usr/lib/python3.10/site-packages (from wandb) (67.6.1)\n","Requirement already satisfied: appdirs>=1.4.3 in /usr/lib/python3.10/site-packages (from wandb) (1.4.4)\n","Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /home/sooraj/.local/lib/python3.10/site-packages (from wandb) (3.20.1)\n","Requirement already satisfied: sentry-sdk>=1.0.0 in /home/sooraj/.local/lib/python3.10/site-packages (from wandb) (1.9.0)\n","Requirement already satisfied: pathtools in /home/sooraj/.local/lib/python3.10/site-packages (from wandb) (0.1.2)\n","Requirement already satisfied: GitPython>=1.0.0 in /home/sooraj/.local/lib/python3.10/site-packages (from wandb) (3.1.30)\n","Requirement already satisfied: docker-pycreds>=0.4.0 in /home/sooraj/.local/lib/python3.10/site-packages (from wandb) (0.4.0)\n","Requirement already satisfied: setproctitle in /usr/lib/python3.10/site-packages (from wandb) (1.3.2)\n","Requirement already satisfied: python-dateutil>=2.7.0 in /home/sooraj/.local/lib/python3.10/site-packages (from arrow<3.0,>=1.2.0->lightning) (2.8.2)\n","Requirement already satisfied: soupsieve>1.2 in /usr/lib/python3.10/site-packages (from beautifulsoup4<6.0,>=4.8.0->lightning) (2.4)\n","Requirement already satisfied: pytz in /home/sooraj/.local/lib/python3.10/site-packages (from dateutils<2.0->lightning) (2022.1)\n","Requirement already satisfied: ordered-set<4.2.0,>=4.0.2 in /usr/lib/python3.10/site-packages (from deepdiff<8.0,>=5.7.0->lightning) (4.1.0)\n","Requirement already satisfied: six>=1.4.0 in /usr/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n","Requirement already satisfied: anyio<5,>=3.4.0 in /home/sooraj/.local/lib/python3.10/site-packages (from starlette<2.0->lightning) (3.6.1)\n","Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /home/sooraj/.local/lib/python3.10/site-packages (from fsspec[http]<2025.0,>2021.06.0->lightning) (3.8.3)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /home/sooraj/.local/lib/python3.10/site-packages (from GitPython>=1.0.0->wandb) (4.0.10)\n","Requirement already satisfied: python-editor>=1.0.4 in /home/sooraj/.local/lib/python3.10/site-packages (from inquirer<5.0,>=2.10.0->lightning) (1.0.4)\n","Requirement already satisfied: readchar>=3.0.6 in /home/sooraj/.local/lib/python3.10/site-packages (from inquirer<5.0,>=2.10.0->lightning) (4.0.5)\n","Requirement already satisfied: blessed>=1.19.0 in /home/sooraj/.local/lib/python3.10/site-packages (from inquirer<5.0,>=2.10.0->lightning) (1.20.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /home/sooraj/.local/lib/python3.10/site-packages (from Jinja2<5.0->lightning) (2.1.1)\n","Requirement already satisfied: pyjwt in /home/sooraj/.local/lib/python3.10/site-packages (from lightning-cloud>=0.5.31->lightning) (2.6.0)\n","Requirement already satisfied: idna<4,>=2.5 in /home/sooraj/.local/lib/python3.10/site-packages (from requests<4.0->lightning) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3.10/site-packages (from requests<4.0->lightning) (2022.12.7)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /home/sooraj/.local/lib/python3.10/site-packages (from requests<4.0->lightning) (2.1.1)\n","Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /home/sooraj/.local/lib/python3.10/site-packages (from rich<15.0,>=12.3.0->lightning) (2.2.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/lib/python3.10/site-packages (from rich<15.0,>=12.3.0->lightning) (2.14.0)\n","Requirement already satisfied: itsdangerous<3.0.0,>=2.0.1 in /home/sooraj/.local/lib/python3.10/site-packages (from starsessions<2.0,>=1.2.1->lightning) (2.1.2)\n","Requirement already satisfied: h11>=0.8 in /home/sooraj/.local/lib/python3.10/site-packages (from uvicorn<2.0->lightning) (0.12.0)\n","Requirement already satisfied: asgiref>=3.4.0 in /home/sooraj/.local/lib/python3.10/site-packages (from uvicorn<2.0->lightning) (3.5.1)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /home/sooraj/.local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>2021.06.0->lightning) (1.8.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /home/sooraj/.local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>2021.06.0->lightning) (1.3.3)\n","Requirement already satisfied: attrs>=17.3.0 in /home/sooraj/.local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>2021.06.0->lightning) (21.4.0)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/sooraj/.local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>2021.06.0->lightning) (4.0.2)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /home/sooraj/.local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>2021.06.0->lightning) (6.0.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /home/sooraj/.local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>2021.06.0->lightning) (1.3.1)\n","Requirement already satisfied: sniffio>=1.1 in /home/sooraj/.local/lib/python3.10/site-packages (from anyio<5,>=3.4.0->starlette<2.0->lightning) (1.2.0)\n","Requirement already satisfied: wcwidth>=0.1.4 in /home/sooraj/.local/lib/python3.10/site-packages (from blessed>=1.19.0->inquirer<5.0,>=2.10.0->lightning) (0.2.5)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /home/sooraj/.local/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (5.0.0)\n","Requirement already satisfied: mdurl~=0.1 in /home/sooraj/.local/lib/python3.10/site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich<15.0,>=12.3.0->lightning) (0.1.2)\n","Requirement already satisfied: ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,<6.0.0,>=4.0.1 in /home/sooraj/.local/lib/python3.10/site-packages (from fastapi<0.89.0->lightning) (5.7.0)\n","Requirement already satisfied: orjson<4.0.0,>=3.2.1 in /home/sooraj/.local/lib/python3.10/site-packages (from fastapi<0.89.0->lightning) (3.8.3)\n","Requirement already satisfied: python-multipart<0.0.6,>=0.0.5 in /home/sooraj/.local/lib/python3.10/site-packages (from fastapi<0.89.0->lightning) (0.0.5)\n","Requirement already satisfied: email_validator<2.0.0,>=1.1.1 in /home/sooraj/.local/lib/python3.10/site-packages (from fastapi<0.89.0->lightning) (1.3.1)\n","Requirement already satisfied: dnspython>=1.15.0 in /home/sooraj/.local/lib/python3.10/site-packages (from email_validator<2.0.0,>=1.1.1->fastapi<0.89.0->lightning) (2.3.0)\n","Requirement already satisfied: python-dotenv>=0.13 in /home/sooraj/.local/lib/python3.10/site-packages (from uvicorn<2.0->lightning) (1.0.0)\n","Requirement already satisfied: watchgod>=0.6 in /home/sooraj/.local/lib/python3.10/site-packages (from uvicorn<2.0->lightning) (0.8.2)\n","Requirement already satisfied: httptools>=0.4.0 in /home/sooraj/.local/lib/python3.10/site-packages (from uvicorn<2.0->lightning) (0.5.0)\n","Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /home/sooraj/.local/lib/python3.10/site-packages (from uvicorn<2.0->lightning) (0.17.0)\n","Requirement already satisfied: platformdirs in /home/sooraj/.local/lib/python3.10/site-packages (from setuptools->wandb) (2.5.2)\n","Requirement already satisfied: jaraco.text in /usr/lib/python3.10/site-packages (from setuptools->wandb) (3.11.1)\n","Requirement already satisfied: more-itertools in /usr/lib/python3.10/site-packages (from setuptools->wandb) (9.1.0)\n","Requirement already satisfied: tomli in /usr/lib/python3.10/site-packages (from setuptools->wandb) (2.0.1)\n","Requirement already satisfied: validate-pyproject in /usr/lib/python3.10/site-packages (from setuptools->wandb) (0.12.2.post1.dev0+g2940279.d20230328)\n","Requirement already satisfied: jaraco.context>=4.1 in /usr/lib/python3.10/site-packages (from jaraco.text->setuptools->wandb) (4.3.0)\n","Requirement already satisfied: inflect in /usr/lib/python3.10/site-packages (from jaraco.text->setuptools->wandb) (6.0.4)\n","Requirement already satisfied: autocommand in /usr/lib/python3.10/site-packages (from jaraco.text->setuptools->wandb) (2.2.2)\n","Requirement already satisfied: jaraco.functools in /usr/lib/python3.10/site-packages (from jaraco.text->setuptools->wandb) (3.6.0)\n","Requirement already satisfied: fastjsonschema<=3,>=2.16.2 in /home/sooraj/.local/lib/python3.10/site-packages (from validate-pyproject->setuptools->wandb) (2.16.2)\n","\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"]}],"source":["!pip install lightning wandb "]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-04-14T13:01:58.579693Z","iopub.status.busy":"2023-04-14T13:01:58.578344Z","iopub.status.idle":"2023-04-14T13:02:01.251903Z","shell.execute_reply":"2023-04-14T13:02:01.250659Z","shell.execute_reply.started":"2023-04-14T13:01:58.579610Z"},"trusted":true},"outputs":[],"source":["import torch\n","from torch import nn\n","import pandas as pd\n","import numpy as np\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader\n","import lightning.pytorch as pl\n","from torch import optim\n","from torch.utils.data.sampler import SubsetRandomSampler\n","from torch.utils.data import random_split\n","import wandb\n","from pytorch_lightning.loggers import WandbLogger\n","import random\n","import torch.nn.functional as F"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-04-14T13:03:03.632390Z","iopub.status.busy":"2023-04-14T13:03:03.631973Z","iopub.status.idle":"2023-04-14T13:03:03.638675Z","shell.execute_reply":"2023-04-14T13:03:03.637395Z","shell.execute_reply.started":"2023-04-14T13:03:03.632354Z"},"trusted":true},"outputs":[],"source":["# common_path = \"/kaggle/input/aksharantar/aksharantar_sampled/hin/\"\n","common_path = \"./aksharantar_sampled/hin/\"\n","train_path = common_path +'hin_train.csv'\n","test_path = common_path +'hin_test.csv'\n","val_path = common_path +'hin_valid.csv'"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-04-14T13:03:58.489665Z","iopub.status.busy":"2023-04-14T13:03:58.489175Z","iopub.status.idle":"2023-04-14T13:03:58.644766Z","shell.execute_reply":"2023-04-14T13:03:58.643523Z","shell.execute_reply.started":"2023-04-14T13:03:58.489620Z"},"trusted":true},"outputs":[],"source":["train_data = pd.read_csv(train_path)\n","val_data = pd.read_csv(val_path)"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"data":{"text/plain":["array(['बिन्द्या', 'किरणकांत', 'यज्ञोपवीत', ..., 'असहमतों', 'सुलगायीं',\n","       'अंचुतेंगु'], dtype=object)"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["train_data.iloc[:, 1].values"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-04-14T13:06:00.344685Z","iopub.status.busy":"2023-04-14T13:06:00.344155Z","iopub.status.idle":"2023-04-14T13:06:00.352480Z","shell.execute_reply":"2023-04-14T13:06:00.350684Z","shell.execute_reply.started":"2023-04-14T13:06:00.344637Z"},"trusted":true},"outputs":[],"source":["train_input = train_data.iloc[:, 0].values\n","val_input = val_data.iloc[:, 0].values\n","train_output = train_data.iloc[:, 1].values\n","val_output = val_data.iloc[:, 1].values"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-04-14T13:07:15.243618Z","iopub.status.busy":"2023-04-14T13:07:15.243106Z","iopub.status.idle":"2023-04-14T13:07:15.252119Z","shell.execute_reply":"2023-04-14T13:07:15.250270Z","shell.execute_reply.started":"2023-04-14T13:07:15.243575Z"},"trusted":true},"outputs":[],"source":["def get_dataloaders(path):\n","    data = pd.read_csv(path)\n","    data_input = data.iloc[:, 0].values\n","    data_output = data.iloc[:, 1].values\n","    return data_input, data_output"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["eng_to_int = {}\n","hin_to_int = {}\n","eng_to_int['SOW'] = 0\n","eng_to_int['EOW'] = 1\n","hin_to_int['SOW'] = 0\n","hin_to_int['EOW'] = 1\n","count = 2\n","for i in range(97, 123):\n","    eng_to_int[chr(i)] = count \n","    count += 1\n","eng_to_int['PAD'] = count\n","count = 2\n","for i in range(2304, 2432):\n","    hin_to_int[chr(i)] = count\n","    count += 1\n","hin_to_int['PAD'] = count\n","eng_max_len = 26\n","hin_max_len = 22\n","def convert_word_to_tensor(word, language):\n","    if language == 'eng':\n","        char_to_int = eng_to_int\n","        max_len  =eng_max_len\n","    else:\n","        char_to_int = hin_to_int\n","        max_len = hin_max_len\n","    ascii = [char_to_int['SOW']]\n","    ascii += [char_to_int[c] for c in word]\n","    ascii.append(1) # for end of word\n","    for x in range(max_len - len(ascii)):\n","        ascii.append(char_to_int['PAD'])\n","    ascii = torch.tensor(ascii, device=device)\n","    # one_hot = [torch.zeros(1, 1, 256) for _ in ascii]\n","    # for i, c in enumerate(ascii):\n","        # one_hot[i][0][0][c] = 1\n","    return ascii"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"data":{"text/plain":["'अ'"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["chr(2309)"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"data":{"text/plain":["tensor([  0,  56,  58,  79,  38,  79,  50,  64,  25,  64,  50,   1, 130, 130,\n","        130, 130, 130, 130, 130, 130, 130, 130])"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["convert_word_to_tensor('शस्त्रागार', 'hin')"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"data":{"text/plain":["tensor([  0,   7,   1, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130,\n","        130, 130, 130, 130, 130, 130, 130, 130])"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["convert_word_to_tensor('अ', 'hin')"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Create dataloaders"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["class CustomDataset(torch.utils.data.Dataset):\n","    def __init__(self, input, output):\n","        self.input = input\n","        self.output = output\n","    def __len__(self):\n","        return len(self.input)\n","    def __getitem__(self, idx):\n","        return convert_word_to_tensor(self.input[idx], 'eng'), convert_word_to_tensor(self.output[idx], 'hin')"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["train_loader = CustomDataset(train_input, train_output)\n","val_loader = CustomDataset(val_input, val_output)\n","train_loader = DataLoader(train_loader, batch_size=128, shuffle=True)\n","val_loader = DataLoader(train_loader, batch_size=128, shuffle=True)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Encoder"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["class Encoder(nn.Module):\n","    def __init__(self, input_size, hidden_size, cell_type, dropout):\n","        super().__init__()\n","        self.hidden_size = hidden_size\n","        self.cell_type = cell_type\n","        self.dropout = dropout\n","        self.embedding = nn.Embedding(input_size, hidden_size)\n","        self.rnn = self.find_cell_type(cell_type)(hidden_size, hidden_size, batch_first=True)\n","        self.dropout = nn.Dropout(dropout)\n","        \n","\n","    def find_cell_type(self, cell_type):\n","        if cell_type == \"GRU\":\n","            return nn.GRU\n","        elif cell_type == \"LSTM\":\n","            return nn.LSTM\n","        else:\n","            return nn.RNN\n","\n","    def forward(self, input, hidden):\n","        embedded = self.embedding(input).squeeze()\n","        output, hidden = self.rnn(embedded, hidden)\n","        return output, hidden\n","\n","    def initHidden(self, batch_size=1):\n","        weights = torch.zeros(1, batch_size,  self.hidden_size, device=device)\n","        torch.nn.init.xavier_normal_(weights)\n","        return weights"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[ 0,  3, 10,  ..., 28, 28, 28],\n","        [ 0, 22,  8,  ..., 28, 28, 28],\n","        [ 0,  5, 16,  ..., 28, 28, 28],\n","        ...,\n","        [ 0, 14,  2,  ..., 28, 28, 28],\n","        [ 0, 14,  2,  ..., 28, 28, 28],\n","        [ 0, 14,  2,  ..., 28, 28, 28]])\n","tensor([[  0,  46,  65,  ..., 130, 130, 130],\n","        [  0,  11,  25,  ..., 130, 130, 130],\n","        [  0,  40,  77,  ..., 130, 130, 130],\n","        ...,\n","        [  0,  48,  64,  ..., 130, 130, 130],\n","        [  0,  48,  59,  ..., 130, 130, 130],\n","        [  0,  48,  41,  ..., 130, 130, 130]])\n","tensor([[[ 0.0948, -0.0482, -0.3053,  ..., -0.0750,  0.1926, -0.4758],\n","         [-0.2599, -0.3996, -0.5173,  ...,  0.0783,  0.1406, -0.0428],\n","         [ 0.2098,  0.2435, -0.4361,  ..., -0.0961, -0.0802, -0.1291],\n","         ...,\n","         [ 0.5220,  0.4135,  0.2197,  ..., -0.3724, -0.1790,  0.5385],\n","         [ 0.5220,  0.4147,  0.2198,  ..., -0.3724, -0.1791,  0.5384],\n","         [ 0.5220,  0.4156,  0.2199,  ..., -0.3724, -0.1791,  0.5384]],\n","\n","        [[ 0.0994, -0.0706, -0.2981,  ..., -0.0807,  0.1951, -0.4783],\n","         [-0.0011, -0.2418, -0.1973,  ...,  0.2316, -0.3127, -0.2855],\n","         [ 0.0959, -0.4607, -0.4712,  ...,  0.1226, -0.0523, -0.3191],\n","         ...,\n","         [ 0.5216,  0.4068,  0.2176,  ..., -0.3722, -0.1763,  0.5399],\n","         [ 0.5217,  0.4092,  0.2181,  ..., -0.3723, -0.1768,  0.5399],\n","         [ 0.5217,  0.4111,  0.2185,  ..., -0.3723, -0.1773,  0.5397]],\n","\n","        [[ 0.0930, -0.0635, -0.2944,  ..., -0.0700,  0.1892, -0.4815],\n","         [ 0.2935, -0.1979, -0.4440,  ...,  0.2664, -0.0242, -0.4817],\n","         [-0.0072, -0.4197, -0.0585,  ..., -0.0859,  0.3478, -0.2290],\n","         ...,\n","         [ 0.5208,  0.4082,  0.2185,  ..., -0.3721, -0.1767,  0.5387],\n","         [ 0.5211,  0.4105,  0.2188,  ..., -0.3722, -0.1772,  0.5387],\n","         [ 0.5213,  0.4122,  0.2191,  ..., -0.3722, -0.1776,  0.5386]],\n","\n","        ...,\n","\n","        [[ 0.0996, -0.0658, -0.3058,  ..., -0.0824,  0.1837, -0.4802],\n","         [-0.0101, -0.1037, -0.2037,  ..., -0.0938,  0.1274, -0.0580],\n","         [ 0.0066, -0.4136, -0.3526,  ..., -0.5746,  0.0312, -0.3020],\n","         ...,\n","         [ 0.5204,  0.4018,  0.2166,  ..., -0.3719, -0.1751,  0.5383],\n","         [ 0.5207,  0.4055,  0.2173,  ..., -0.3720, -0.1758,  0.5387],\n","         [ 0.5210,  0.4083,  0.2179,  ..., -0.3721, -0.1764,  0.5389]],\n","\n","        [[ 0.1022, -0.0695, -0.2954,  ..., -0.0726,  0.1784, -0.4843],\n","         [-0.0094, -0.1070, -0.1975,  ..., -0.0856,  0.1235, -0.0590],\n","         [ 0.0068, -0.4156, -0.3496,  ..., -0.5724,  0.0299, -0.3030],\n","         ...,\n","         [ 0.5197,  0.3894,  0.2151,  ..., -0.3719, -0.1763,  0.5423],\n","         [ 0.5203,  0.3962,  0.2163,  ..., -0.3721, -0.1763,  0.5420],\n","         [ 0.5208,  0.4013,  0.2171,  ..., -0.3722, -0.1766,  0.5416]],\n","\n","        [[ 0.0961, -0.0676, -0.3061,  ..., -0.0701,  0.1985, -0.4799],\n","         [-0.0110, -0.1046, -0.2031,  ..., -0.0843,  0.1381, -0.0627],\n","         [ 0.0060, -0.4146, -0.3497,  ..., -0.5716,  0.0357, -0.3059],\n","         ...,\n","         [ 0.5216,  0.3998,  0.2121,  ..., -0.3716, -0.1708,  0.5397],\n","         [ 0.5215,  0.4030,  0.2137,  ..., -0.3719, -0.1722,  0.5403],\n","         [ 0.5214,  0.4056,  0.2150,  ..., -0.3721, -0.1734,  0.5405]]],\n","       grad_fn=<TransposeBackward1>)\n","torch.Size([128, 26, 64])\n"]}],"source":["enc = Encoder(len(eng_to_int) + 1, 64, \"GRU\", 0.1)\n","hidden = enc.initHidden(128)\n","for x, y in train_loader:\n","    print(x)\n","    print(y)\n","    out, hidden = enc(x, hidden)\n","    print(out)\n","    print(out.shape)\n","    break"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Decoder"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":["class Decoder(nn.Module):\n","    def __init__(self, output_size, hidden_size, cell_type, dropout):\n","        super().__init__()\n","        self.hidden_size = hidden_size\n","        self.dropout = dropout\n","        self.cell_type = cell_type\n","        self.embedding = nn.Embedding(output_size, hidden_size)\n","        self.rnn = self.find_cell_type(cell_type)(hidden_size, hidden_size, batch_first=True)\n","        self.linear = nn.Linear(hidden_size, output_size)\n","        self.dropout = nn.Dropout(dropout)\n","        self.softmax = nn.Softmax(dim=1)\n","\n","    def find_cell_type(self, cell_type):\n","        if cell_type == \"GRU\":\n","            return nn.GRU\n","        elif cell_type == \"LSTM\":\n","            return nn.LSTM\n","        else:\n","            return nn.RNN\n","\n","    def forward(self, input, hidden):\n","        embedded = self.embedding(input)\n","        output, hidden = self.rnn(embedded, hidden)\n","        linear_output = self.linear(output)\n","        # print(\"decoder: \", output, output.squeeze(0))\n","        exp_x = torch.exp(linear_output)\n","        sum_x = torch.sum(exp_x, dim=2, keepdim=True)\n","        prob_output = exp_x / sum_x\n","        # output = torch.argmax(output, dim=1)\n","        return prob_output, hidden\n","\n","    def initHidden(self):\n","        weights = torch.zeros(1, 1, self.hidden_size, device=device)\n","        torch.nn.init.xavier_normal_(weights)\n","        return weights"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Train the encoder-decoder model"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[],"source":["class EncoderDecoder(pl.LightningModule):\n","    def __init__(self, input_size, output_size, hidden_size, cell_type, dropout, learning_rate=0.1):\n","        super().__init__()\n","        self.encoder = Encoder(input_size, hidden_size, cell_type, dropout)\n","        self.decoder = Decoder(output_size, hidden_size, cell_type, dropout)\n","        self.lr = learning_rate\n","\n","    def forward(self, input, target):\n","        _, hidden = self.encoder(input, self.encoder.initHidden(input.shape[0]))\n","\n","        # Initialize the decoder hidden state with the encoder hidden state\n","        decoder_hidden = hidden\n","\n","        # Initialize the decoder input with the <SOS> token\n","        decoder_input = target[:, 0]\n","\n","        # Initialize the output sequence\n","        output_sequence = torch.zeros(target.shape[0], target.shape[1], self.decoder.linear.out_features, device=device)\n","\n","        # Feed the decoder input and hidden state through the decoder for each token in the output sequence\n","        for i in range(1, target.shape[1]):\n","            decoder_output, decoder_hidden = self.decoder(decoder_input.unsqueeze(1), decoder_hidden)\n","            output_sequence[:, i] = decoder_output.squeeze(1)\n","            decoder_input = decoder_output.argmax(dim=2).squeeze(1)\n","        output_sequence =  output_sequence.transpose(1, 2)\n","        return output_sequence\n","\n","    def forward_teacher_force(self, input, target):\n","        # Encode the input sequence to get the final hidden state\n","        _, hidden = self.encoder(input, self.encoder.initHidden(input.shape[0]))\n","\n","        # Initialize the decoder hidden state with the encoder hidden state\n","        decoder_hidden = hidden\n","\n","        # Initialize the decoder input with the <SOS> token\n","        decoder_input = target[:, 0]\n","\n","        # Initialize the output sequence\n","        output_sequence = torch.zeros(target.shape[0], target.shape[1], self.decoder.linear.out_features, device=device)\n","\n","        # Feed the decoder input and hidden state through the decoder for each token in the output sequence\n","        for i in range(1, target.shape[1]):\n","            decoder_output, decoder_hidden = self.decoder(decoder_input.unsqueeze(1), decoder_hidden)\n","            output_sequence[:, i] = decoder_output.squeeze(1)\n","            decoder_input = target[:, i]\n","        output_sequence =  output_sequence.transpose(1, 2)\n","        return output_sequence\n","\n","    def training_step(self, batch, batch_idx):\n","        input, target = batch\n","        if random.random()  < 0.5:\n","            output = self(input, target)\n","        else: \n","            output = self.forward_teacher_force(input, target)\n","        loss = F.cross_entropy(output, target)\n","        self.log('train_loss', loss, on_epoch=True, on_step=True, prog_bar=True)\n","        return loss\n","\n","    def validation_step(self, batch, batch_idx):\n","        input, target = batch\n","        output = self(input, target[:, :-1])\n","        loss = F.cross_entropy(output.reshape(-1, output.shape[-1]), target[:, 1:].reshape(-1))\n","        self.log('val_loss', loss, on_epoch=True, on_step=True, prog_bar=True)\n","\n","    def configure_optimizers(self):\n","        return torch.optim.Adam(self.parameters(), lr=self.lr)\n"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[],"source":["model = EncoderDecoder(len(eng_to_int)+1, len(hin_to_int)+1, 64, \"RNN\", 0.1)"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["GPU available: False, used: False\n","TPU available: False, using: 0 TPU cores\n","IPU available: False, using: 0 IPUs\n","HPU available: False, using: 0 HPUs\n","/home/sooraj/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/configuration_validator.py:72: PossibleUserWarning: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n","  rank_zero_warn(\n","\n","  | Name    | Type    | Params\n","------------------------------------\n","0 | encoder | Encoder | 10.2 K\n","1 | decoder | Decoder | 25.3 K\n","------------------------------------\n","35.6 K    Trainable params\n","0         Non-trainable params\n","35.6 K    Total params\n","0.142     Total estimated model params size (MB)\n","/home/sooraj/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n","  rank_zero_warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"479948c007df4211952163750d43a5b2","version_major":2,"version_minor":0},"text/plain":["Training: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"ename":"RuntimeError","evalue":"For unbatched 2-D input, hx should also be 2-D but got 3-D tensor","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[1;32m/home/sooraj/sem/dl/assignment-3/cs6910-assignment-3.ipynb Cell 25\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/sooraj/sem/dl/assignment-3/cs6910-assignment-3.ipynb#X33sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m trainer \u001b[39m=\u001b[39m pl\u001b[39m.\u001b[39mTrainer(max_epochs\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/sooraj/sem/dl/assignment-3/cs6910-assignment-3.ipynb#X33sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m trainer\u001b[39m.\u001b[39;49mfit(model, train_loader)\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:520\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    518\u001b[0m model \u001b[39m=\u001b[39m _maybe_unwrap_optimized(model)\n\u001b[1;32m    519\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39m_lightning_module \u001b[39m=\u001b[39m model\n\u001b[0;32m--> 520\u001b[0m call\u001b[39m.\u001b[39;49m_call_and_handle_interrupt(\n\u001b[1;32m    521\u001b[0m     \u001b[39mself\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\n\u001b[1;32m    522\u001b[0m )\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py:44\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[39mreturn\u001b[39;00m trainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mlauncher\u001b[39m.\u001b[39mlaunch(trainer_fn, \u001b[39m*\u001b[39margs, trainer\u001b[39m=\u001b[39mtrainer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m     43\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 44\u001b[0m         \u001b[39mreturn\u001b[39;00m trainer_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     46\u001b[0m \u001b[39mexcept\u001b[39;00m _TunerExitException:\n\u001b[1;32m     47\u001b[0m     _call_teardown_hook(trainer)\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:559\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    549\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data_connector\u001b[39m.\u001b[39mattach_data(\n\u001b[1;32m    550\u001b[0m     model, train_dataloaders\u001b[39m=\u001b[39mtrain_dataloaders, val_dataloaders\u001b[39m=\u001b[39mval_dataloaders, datamodule\u001b[39m=\u001b[39mdatamodule\n\u001b[1;32m    551\u001b[0m )\n\u001b[1;32m    553\u001b[0m ckpt_path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_checkpoint_connector\u001b[39m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    554\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mfn,\n\u001b[1;32m    555\u001b[0m     ckpt_path,\n\u001b[1;32m    556\u001b[0m     model_provided\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    557\u001b[0m     model_connected\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlightning_module \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    558\u001b[0m )\n\u001b[0;32m--> 559\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run(model, ckpt_path\u001b[39m=\u001b[39;49mckpt_path)\n\u001b[1;32m    561\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mstopped\n\u001b[1;32m    562\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:935\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    930\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_signal_connector\u001b[39m.\u001b[39mregister_signal_handlers()\n\u001b[1;32m    932\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[1;32m    933\u001b[0m \u001b[39m# RUN THE TRAINER\u001b[39;00m\n\u001b[1;32m    934\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[0;32m--> 935\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_stage()\n\u001b[1;32m    937\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[1;32m    938\u001b[0m \u001b[39m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[1;32m    939\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[1;32m    940\u001b[0m log\u001b[39m.\u001b[39mdebug(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m: trainer tearing down\u001b[39m\u001b[39m\"\u001b[39m)\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:978\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    976\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_run_sanity_check()\n\u001b[1;32m    977\u001b[0m     \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mset_detect_anomaly(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_detect_anomaly):\n\u001b[0;32m--> 978\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit_loop\u001b[39m.\u001b[39;49mrun()\n\u001b[1;32m    979\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    980\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnexpected state \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:201\u001b[0m, in \u001b[0;36m_FitLoop.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    200\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_start()\n\u001b[0;32m--> 201\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madvance()\n\u001b[1;32m    202\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_end()\n\u001b[1;32m    203\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_restarting \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:354\u001b[0m, in \u001b[0;36m_FitLoop.advance\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data_fetcher\u001b[39m.\u001b[39msetup(combined_loader)\n\u001b[1;32m    353\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mprofile(\u001b[39m\"\u001b[39m\u001b[39mrun_training_epoch\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> 354\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mepoch_loop\u001b[39m.\u001b[39;49mrun(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data_fetcher)\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/lightning/pytorch/loops/training_epoch_loop.py:133\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.run\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdone:\n\u001b[1;32m    132\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 133\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madvance(data_fetcher)\n\u001b[1;32m    134\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_end()\n\u001b[1;32m    135\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_restarting \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/lightning/pytorch/loops/training_epoch_loop.py:218\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.advance\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[39mwith\u001b[39;00m trainer\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mprofile(\u001b[39m\"\u001b[39m\u001b[39mrun_training_batch\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[39mif\u001b[39;00m trainer\u001b[39m.\u001b[39mlightning_module\u001b[39m.\u001b[39mautomatic_optimization:\n\u001b[1;32m    217\u001b[0m         \u001b[39m# in automatic optimization, there can only be one optimizer\u001b[39;00m\n\u001b[0;32m--> 218\u001b[0m         batch_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mautomatic_optimization\u001b[39m.\u001b[39;49mrun(trainer\u001b[39m.\u001b[39;49moptimizers[\u001b[39m0\u001b[39;49m], kwargs)\n\u001b[1;32m    219\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    220\u001b[0m         batch_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmanual_optimization\u001b[39m.\u001b[39mrun(kwargs)\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py:185\u001b[0m, in \u001b[0;36m_AutomaticOptimization.run\u001b[0;34m(self, optimizer, kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m         closure()\n\u001b[1;32m    180\u001b[0m \u001b[39m# ------------------------------\u001b[39;00m\n\u001b[1;32m    181\u001b[0m \u001b[39m# BACKWARD PASS\u001b[39;00m\n\u001b[1;32m    182\u001b[0m \u001b[39m# ------------------------------\u001b[39;00m\n\u001b[1;32m    183\u001b[0m \u001b[39m# gradient update with accumulated gradients\u001b[39;00m\n\u001b[1;32m    184\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 185\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_optimizer_step(kwargs\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mbatch_idx\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m0\u001b[39;49m), closure)\n\u001b[1;32m    187\u001b[0m result \u001b[39m=\u001b[39m closure\u001b[39m.\u001b[39mconsume_result()\n\u001b[1;32m    188\u001b[0m \u001b[39mif\u001b[39;00m result\u001b[39m.\u001b[39mloss \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py:261\u001b[0m, in \u001b[0;36m_AutomaticOptimization._optimizer_step\u001b[0;34m(self, batch_idx, train_step_and_backward_closure)\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptim_progress\u001b[39m.\u001b[39moptimizer\u001b[39m.\u001b[39mstep\u001b[39m.\u001b[39mincrement_ready()\n\u001b[1;32m    260\u001b[0m \u001b[39m# model hook\u001b[39;00m\n\u001b[0;32m--> 261\u001b[0m call\u001b[39m.\u001b[39;49m_call_lightning_module_hook(\n\u001b[1;32m    262\u001b[0m     trainer,\n\u001b[1;32m    263\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39moptimizer_step\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    264\u001b[0m     trainer\u001b[39m.\u001b[39;49mcurrent_epoch,\n\u001b[1;32m    265\u001b[0m     batch_idx,\n\u001b[1;32m    266\u001b[0m     optimizer,\n\u001b[1;32m    267\u001b[0m     train_step_and_backward_closure,\n\u001b[1;32m    268\u001b[0m )\n\u001b[1;32m    270\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m should_accumulate:\n\u001b[1;32m    271\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptim_progress\u001b[39m.\u001b[39moptimizer\u001b[39m.\u001b[39mstep\u001b[39m.\u001b[39mincrement_completed()\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py:142\u001b[0m, in \u001b[0;36m_call_lightning_module_hook\u001b[0;34m(trainer, hook_name, pl_module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    139\u001b[0m pl_module\u001b[39m.\u001b[39m_current_fx_name \u001b[39m=\u001b[39m hook_name\n\u001b[1;32m    141\u001b[0m \u001b[39mwith\u001b[39;00m trainer\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mprofile(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m[LightningModule]\u001b[39m\u001b[39m{\u001b[39;00mpl_module\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00mhook_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> 142\u001b[0m     output \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    144\u001b[0m \u001b[39m# restore current_fx when nested context\u001b[39;00m\n\u001b[1;32m    145\u001b[0m pl_module\u001b[39m.\u001b[39m_current_fx_name \u001b[39m=\u001b[39m prev_fx_name\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/lightning/pytorch/core/module.py:1265\u001b[0m, in \u001b[0;36mLightningModule.optimizer_step\u001b[0;34m(self, epoch, batch_idx, optimizer, optimizer_closure)\u001b[0m\n\u001b[1;32m   1226\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39moptimizer_step\u001b[39m(\n\u001b[1;32m   1227\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   1228\u001b[0m     epoch: \u001b[39mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1231\u001b[0m     optimizer_closure: Optional[Callable[[], Any]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1232\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1233\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1234\u001b[0m \u001b[39m    Override this method to adjust the default way the :class:`~lightning.pytorch.trainer.trainer.Trainer` calls\u001b[39;00m\n\u001b[1;32m   1235\u001b[0m \u001b[39m    the optimizer.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1263\u001b[0m \u001b[39m                    pg[\"lr\"] = lr_scale * self.learning_rate\u001b[39;00m\n\u001b[1;32m   1264\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1265\u001b[0m     optimizer\u001b[39m.\u001b[39;49mstep(closure\u001b[39m=\u001b[39;49moptimizer_closure)\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:158\u001b[0m, in \u001b[0;36mLightningOptimizer.step\u001b[0;34m(self, closure, **kwargs)\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[39mraise\u001b[39;00m MisconfigurationException(\u001b[39m\"\u001b[39m\u001b[39mWhen `optimizer.step(closure)` is called, the closure should be callable\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    157\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_strategy \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 158\u001b[0m step_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_strategy\u001b[39m.\u001b[39;49moptimizer_step(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_optimizer, closure, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    160\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_on_after_step()\n\u001b[1;32m    162\u001b[0m \u001b[39mreturn\u001b[39;00m step_output\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py:224\u001b[0m, in \u001b[0;36mStrategy.optimizer_step\u001b[0;34m(self, optimizer, closure, model, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[39m# TODO(fabric): remove assertion once strategy's optimizer_step typing is fixed\u001b[39;00m\n\u001b[1;32m    223\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(model, pl\u001b[39m.\u001b[39mLightningModule)\n\u001b[0;32m--> 224\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprecision_plugin\u001b[39m.\u001b[39;49moptimizer_step(optimizer, model\u001b[39m=\u001b[39;49mmodel, closure\u001b[39m=\u001b[39;49mclosure, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/lightning/pytorch/plugins/precision/precision_plugin.py:114\u001b[0m, in \u001b[0;36mPrecisionPlugin.optimizer_step\u001b[0;34m(self, optimizer, model, closure, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Hook to run the optimizer step.\"\"\"\u001b[39;00m\n\u001b[1;32m    113\u001b[0m closure \u001b[39m=\u001b[39m partial(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_wrap_closure, model, optimizer, closure)\n\u001b[0;32m--> 114\u001b[0m \u001b[39mreturn\u001b[39;00m optimizer\u001b[39m.\u001b[39;49mstep(closure\u001b[39m=\u001b[39;49mclosure, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/optim/optimizer.py:88\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m profile_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mOptimizer.step#\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.step\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(obj\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\n\u001b[1;32m     87\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mrecord_function(profile_name):\n\u001b[0;32m---> 88\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/optim/adam.py:100\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[39mif\u001b[39;00m closure \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     99\u001b[0m     \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39menable_grad():\n\u001b[0;32m--> 100\u001b[0m         loss \u001b[39m=\u001b[39m closure()\n\u001b[1;32m    102\u001b[0m \u001b[39mfor\u001b[39;00m group \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparam_groups:\n\u001b[1;32m    103\u001b[0m     params_with_grad \u001b[39m=\u001b[39m []\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/lightning/pytorch/plugins/precision/precision_plugin.py:101\u001b[0m, in \u001b[0;36mPrecisionPlugin._wrap_closure\u001b[0;34m(self, model, optimizer, closure)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_wrap_closure\u001b[39m(\n\u001b[1;32m     90\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m     91\u001b[0m     model: \u001b[39m\"\u001b[39m\u001b[39mpl.LightningModule\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     92\u001b[0m     optimizer: Optimizer,\n\u001b[1;32m     93\u001b[0m     closure: Callable[[], Any],\n\u001b[1;32m     94\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[1;32m     95\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"This double-closure allows makes sure the ``closure`` is executed before the\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \u001b[39m    ``on_before_optimizer_step`` hook is called.\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \n\u001b[1;32m     98\u001b[0m \u001b[39m    The closure (generally) runs ``backward`` so this allows inspecting gradients in this hook. This structure is\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \u001b[39m    consistent with the ``PrecisionPlugin`` subclasses that cannot pass ``optimizer.step(closure)`` directly.\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 101\u001b[0m     closure_result \u001b[39m=\u001b[39m closure()\n\u001b[1;32m    102\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_after_closure(model, optimizer)\n\u001b[1;32m    103\u001b[0m     \u001b[39mreturn\u001b[39;00m closure_result\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py:140\u001b[0m, in \u001b[0;36mClosure.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs: Any, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Optional[Tensor]:\n\u001b[0;32m--> 140\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclosure(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    141\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_result\u001b[39m.\u001b[39mloss\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py:126\u001b[0m, in \u001b[0;36mClosure.closure\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mclosure\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs: Any, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ClosureResult:\n\u001b[0;32m--> 126\u001b[0m     step_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_step_fn()\n\u001b[1;32m    128\u001b[0m     \u001b[39mif\u001b[39;00m step_output\u001b[39m.\u001b[39mclosure_loss \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    129\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwarning_cache\u001b[39m.\u001b[39mwarn(\u001b[39m\"\u001b[39m\u001b[39m`training_step` returned `None`. If this was on purpose, ignore this warning...\u001b[39m\u001b[39m\"\u001b[39m)\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py:308\u001b[0m, in \u001b[0;36m_AutomaticOptimization._training_step\u001b[0;34m(self, kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m trainer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\n\u001b[1;32m    307\u001b[0m \u001b[39m# manually capture logged metrics\u001b[39;00m\n\u001b[0;32m--> 308\u001b[0m training_step_output \u001b[39m=\u001b[39m call\u001b[39m.\u001b[39;49m_call_strategy_hook(trainer, \u001b[39m\"\u001b[39;49m\u001b[39mtraining_step\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m*\u001b[39;49mkwargs\u001b[39m.\u001b[39;49mvalues())\n\u001b[1;32m    309\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mpost_training_step()\n\u001b[1;32m    311\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_result_cls\u001b[39m.\u001b[39mfrom_training_step_output(training_step_output, trainer\u001b[39m.\u001b[39maccumulate_grad_batches)\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py:288\u001b[0m, in \u001b[0;36m_call_strategy_hook\u001b[0;34m(trainer, hook_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    285\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m    287\u001b[0m \u001b[39mwith\u001b[39;00m trainer\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mprofile(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m[Strategy]\u001b[39m\u001b[39m{\u001b[39;00mtrainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00mhook_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> 288\u001b[0m     output \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    290\u001b[0m \u001b[39m# restore current_fx when nested context\u001b[39;00m\n\u001b[1;32m    291\u001b[0m pl_module\u001b[39m.\u001b[39m_current_fx_name \u001b[39m=\u001b[39m prev_fx_name\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py:366\u001b[0m, in \u001b[0;36mStrategy.training_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    364\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprecision_plugin\u001b[39m.\u001b[39mtrain_step_context():\n\u001b[1;32m    365\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel, TrainingStep)\n\u001b[0;32m--> 366\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mtraining_step(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n","\u001b[1;32m/home/sooraj/sem/dl/assignment-3/cs6910-assignment-3.ipynb Cell 25\u001b[0m in \u001b[0;36mEncoderDecoder.training_step\u001b[0;34m(self, batch, batch_idx)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sooraj/sem/dl/assignment-3/cs6910-assignment-3.ipynb#X33sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m(\u001b[39minput\u001b[39m, target)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sooraj/sem/dl/assignment-3/cs6910-assignment-3.ipynb#X33sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m \u001b[39melse\u001b[39;00m: \n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/sooraj/sem/dl/assignment-3/cs6910-assignment-3.ipynb#X33sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward_teacher_force(\u001b[39minput\u001b[39;49m, target)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sooraj/sem/dl/assignment-3/cs6910-assignment-3.ipynb#X33sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m loss \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mcross_entropy(output, target)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sooraj/sem/dl/assignment-3/cs6910-assignment-3.ipynb#X33sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlog(\u001b[39m'\u001b[39m\u001b[39mtrain_loss\u001b[39m\u001b[39m'\u001b[39m, loss, on_epoch\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, on_step\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, prog_bar\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n","\u001b[1;32m/home/sooraj/sem/dl/assignment-3/cs6910-assignment-3.ipynb Cell 25\u001b[0m in \u001b[0;36mEncoderDecoder.forward_teacher_force\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sooraj/sem/dl/assignment-3/cs6910-assignment-3.ipynb#X33sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m \u001b[39m# Feed the decoder input and hidden state through the decoder for each token in the output sequence\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sooraj/sem/dl/assignment-3/cs6910-assignment-3.ipynb#X33sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, target\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/sooraj/sem/dl/assignment-3/cs6910-assignment-3.ipynb#X33sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m     decoder_output, decoder_hidden \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdecoder(decoder_input\u001b[39m.\u001b[39;49munsqueeze(\u001b[39m1\u001b[39;49m), hidden)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sooraj/sem/dl/assignment-3/cs6910-assignment-3.ipynb#X33sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m     output_sequence[:, i] \u001b[39m=\u001b[39m decoder_output\u001b[39m.\u001b[39msqueeze(\u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sooraj/sem/dl/assignment-3/cs6910-assignment-3.ipynb#X33sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m     decoder_input \u001b[39m=\u001b[39m target[:, :i]\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n","\u001b[1;32m/home/sooraj/sem/dl/assignment-3/cs6910-assignment-3.ipynb Cell 25\u001b[0m in \u001b[0;36mDecoder.forward\u001b[0;34m(self, input, hidden)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sooraj/sem/dl/assignment-3/cs6910-assignment-3.ipynb#X33sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m, hidden):\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sooraj/sem/dl/assignment-3/cs6910-assignment-3.ipynb#X33sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     embedded \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membedding(\u001b[39minput\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/sooraj/sem/dl/assignment-3/cs6910-assignment-3.ipynb#X33sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     output, hidden \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrnn(embedded, hidden)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sooraj/sem/dl/assignment-3/cs6910-assignment-3.ipynb#X33sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     linear_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlinear(output)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sooraj/sem/dl/assignment-3/cs6910-assignment-3.ipynb#X33sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     \u001b[39m# print(\"decoder: \", output, output.squeeze(0))\u001b[39;00m\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/rnn.py:445\u001b[0m, in \u001b[0;36mRNN.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    443\u001b[0m     \u001b[39mif\u001b[39;00m hx \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    444\u001b[0m         \u001b[39mif\u001b[39;00m hx\u001b[39m.\u001b[39mdim() \u001b[39m!=\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[0;32m--> 445\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m    446\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFor unbatched 2-D input, hx should also be 2-D but got \u001b[39m\u001b[39m{\u001b[39;00mhx\u001b[39m.\u001b[39mdim()\u001b[39m}\u001b[39;00m\u001b[39m-D tensor\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    447\u001b[0m         hx \u001b[39m=\u001b[39m hx\u001b[39m.\u001b[39munsqueeze(\u001b[39m1\u001b[39m)\n\u001b[1;32m    448\u001b[0m \u001b[39melse\u001b[39;00m:\n","\u001b[0;31mRuntimeError\u001b[0m: For unbatched 2-D input, hx should also be 2-D but got 3-D tensor"]}],"source":["trainer = pl.Trainer(max_epochs=10)\n","trainer.fit(model, train_loader)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def evaluate():\n","    input_length = input_tensor.size(0)\n","    target_length = target_tensor.size(0)\n","    encoder_hidden = encoder.initHidden(input_length)\n","\n","    # encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n","\n","    loss = 0\n","\n","    encoder_output, encoder_hidden = encoder(\n","        input_tensor, encoder_hidden)\n","        # encoder_outputs[ei] = encoder_output[0, 0]\n","\n","    decoder_input = torch.tensor([[[0]]] * target_length, device=device)\n","\n","    decoder_hidden = encoder_hidden\n","\n","    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n","    \n","    if use_teacher_forcing:\n","        # Teacher forcing: Feed the target as the next input\n","        for di in range(target_tensor.size(1)):\n","            decoder_output, decoder_hidden = decoder(\n","                decoder_input, decoder_hidden)\n","            # print(decoder_output.shape, target_tensor[:, di].shape)\n","            loss += criterion(decoder_output.squeeze(), target_tensor[:, di].squeeze())\n","            decoder_input = target_tensor[:, di].unsqueeze(1)  # Teacher forcing\n","\n","    else:\n","        # Without teacher forcing: use its own predictions as the next input\n","        for di in range(target_length):\n","            decoder_output, decoder_hidden = decoder(\n","                decoder_input, decoder_hidden[di])\n","            topv, topi = decoder_output.topk(1)\n","            decoder_input = topi.squeeze().detach()  # detach from history as input\n","            loss += criterion(decoder_output, target_tensor[di].squeeze())\n","            if decoder_input.item() == 1:\n","                break\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["int_to_hin = {}\n","for x in hin_to_int.keys():\n","    int_to_hin[hin_to_int[x]] = x"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([26, 1]) torch.Size([1, 64])\n","torch.Size([1, 1]) torch.Size([1, 1, 64])\n","५ॲॲ्ंिफ़ूूँ"]}],"source":["word = \"ghar\"\n","tensor = convert_word_to_tensor(word, 'eng')\n","h0 = torch.zeros(1, 64, device=device)\n","print(tensor.shape, h0.shape)\n","enc_out, enc_hidden = enc(tensor, h0)\n","dec_in = torch.tensor([[0]], device=device)\n","dec_hidden = enc_hidden.view(1, 1, 64)\n","print(dec_in.shape, dec_hidden.shape)\n","for i in range(10):\n","    dec_out, dec_hidden = dec(dec_in, dec_hidden)\n","    topv, topi = dec_out.topk(1)\n","    index = torch.argmax(dec_out)\n","    dec_in = torch.tensor([[index.item()]], device=device)\n","    print(int_to_hin[index.item()], end=\"\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"text/plain":["'ऋ'"]},"execution_count":88,"metadata":{},"output_type":"execute_result"}],"source":["int_to_hin[13]"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Attention model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class Attention(pl.LightningModule):\n","    def __init_(self, hidden_dim):\n","        super().__init__()\n","        self.hidden_dim = hidden_dim\n","        self.attn = nn.Linear(self.hidden_dim * 2, 1)\n","        self.softmax = nn.Softmax(dim=1)\n","\n","    def forward(self, hidden, encoder_outputs):\n","        attn_weights = self.attn(torch.cat((hidden[0], encoder_outputs[0]), 1))\n","        attn_weights = self.softmax(attn_weights)\n","        attn_applied = torch.bmm(attn_weights.unsqueeze(0), encoder_outputs.unsqueeze(0))\n","        return attn_applied\n","    \n","    def initHidden(self):\n","        return torch.zeros(1, 1, self.hidden_dim, device=device)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.10"}},"nbformat":4,"nbformat_minor":4}
