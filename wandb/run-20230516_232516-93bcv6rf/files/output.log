
Epoch 0:   0%|          | 1/1599 [00:00<20:20,  1.31it/s, v_num=v6rf, train_loss_step=5.080, train_acc_step=0.000]
/home/sooraj/.local/lib/python3.11/site-packages/pytorch_lightning/loggers/wandb.py:395: UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.
  rank_zero_warn(
/home/sooraj/.local/lib/python3.11/site-packages/lightning/fabric/connector.py:562: UserWarning: 16 is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!
  rank_zero_warn(
/home/sooraj/.local/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/accelerator_connector.py:517: UserWarning: You passed `Trainer(accelerator='cpu', precision='16-mixed')` but AMP with fp16 is not supported on CPU. Using `precision='bf16-mixed'` instead.
  rank_zero_warn(
Using bfloat16 Automatic Mixed Precision (AMP)
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
  | Name    | Type    | Params
------------------------------------
0 | encoder | Encoder | 770 K
1 | decoder | Decoder | 828 K
------------------------------------
1.6 M     Trainable params
0         Non-trainable params
1.6 M     Total params
6.395     Total estimated model params size (MB)
/home/sooraj/.local/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
/home/sooraj/.local/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.










































































































































































































































































































































































































































































































































































































Epoch 0: 100%|██████████| 1599/1599 [19:35<00:00,  1.36it/s, v_num=v6rf, train_loss_step=0.731, train_acc_step=0.000]



































































































































































































































































































































































































































































































































































































































Epoch 1: 100%|██████████| 1599/1599 [20:00<00:00,  1.33it/s, v_num=v6rf, train_loss_step=0.651, train_acc_step=0.0769, val_loss_step=0.519, val_loss_epoch=0.534, val_acc=0.114, train_loss_epoch=0.867, train_acc_epoch=0.0157]




























































































































































































































































































































































































































































































































































































































Epoch 2: 100%|██████████| 1599/1599 [19:51<00:00,  1.34it/s, v_num=v6rf, train_loss_step=0.561, train_acc_step=0.0769, val_loss_step=0.458, val_loss_epoch=0.440, val_acc=0.184, train_loss_epoch=0.495, train_acc_epoch=0.101]

































































































































































































































































































































































































































































































































































































































Epoch 3: 100%|██████████| 1599/1599 [20:03<00:00,  1.33it/s, v_num=v6rf, train_loss_step=0.267, train_acc_step=0.231, val_loss_step=0.371, val_loss_epoch=0.414, val_acc=0.237, train_loss_epoch=0.405, train_acc_epoch=0.171]





































































































































































































































































































































































































































































































































































































































Epoch 4: 100%|██████████| 1599/1599 [19:58<00:00,  1.33it/s, v_num=v6rf, train_loss_step=0.373, train_acc_step=0.231, val_loss_step=0.329, val_loss_epoch=0.396, val_acc=0.279, train_loss_epoch=0.367, train_acc_epoch=0.213]















Validation DataLoader 0:  98%|█████████▊| 126/128 [00:30<00:00,  4.16it/s]

`Trainer.fit` stopped: `max_epochs=5` reached.